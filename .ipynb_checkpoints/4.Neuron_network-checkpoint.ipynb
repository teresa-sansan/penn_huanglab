{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from test_function import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "x_column = ['SIFT_pred','LRT_pred', 'MA_pred', 'PROVEN_pred', 'SLR_score', 'SIFT_score','LRT_omega', \n",
    "                'MA_score', 'PROVEN_score', 'Grantham', 'HMMEntropy','HMMRelEntropy', 'PredRSAB', 'PredRSAI', \n",
    "                'PredRSAE','PredBFactorF', 'PredBFactorM', 'PredBFactorS', 'PredStabilityH','PredStabilityM', \n",
    "                'PredStabilityL', 'PredSSE', 'PredSSH','PredSSC', 'dscore', 'phyloP_pri', 'phyloP_mam','phyloP_ver','RNA_seq','UNEECON']\n",
    "y_column = 'clinvar_result'\n",
    "\n",
    "omit = pd.read_csv(\"unannotated_omit_uneecon.tsv\", sep = '\\t')\n",
    "y = omit.loc[:,[y_column]].values.flatten()\n",
    "X = omit.loc[:,x_column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.5, random_state = 42) \n",
    "\n",
    "domi = pd.read_csv(\"dominant_std.tsv\", sep = '\\t')\n",
    "recess = pd.read_csv(\"recessive_std.tsv\", sep = '\\t')\n",
    "y_domi = domi.loc[:,[y_column]].values.flatten()\n",
    "X_domi = domi.loc[:,x_column]\n",
    "X_train_domi, X_test_domi, y_train_domi, y_test_domi = train_test_split(X_domi,y_domi, test_size = 0.3, random_state = 42)\n",
    "X_train_domi, X_val_domi, y_train_domi, y_val_domi = train_test_split(X_train_domi, y_train_domi, test_size = 0.5, random_state = 42) \n",
    "\n",
    "y_recess = recess.loc[:,[y_column]].values.flatten()\n",
    "X_recess = recess.loc[:,x_column]\n",
    "X_train_recess, X_test_recess, y_train_recess, y_test_recess = train_test_split(X_recess,y_recess, test_size = 0.3, random_state = 42)\n",
    "X_train_recess, X_val_recess, y_train_recess, y_val_recess = train_test_split(X_train_recess, y_train_recess, test_size = 0.5, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54376, 30)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 2\n",
    "nb_epoch = 100\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim = 1, input_shape = (30,), activation = 'sigmoid'))\n",
    "    model.compile(optimizer = SGD(lr = 0.05), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "domi.model = model\n",
    "recess.model = model\n",
    "unannotated.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 682 samples, validate on 683 samples\n",
      "Epoch 1/300\n",
      "682/682 [==============================] - 0s 21us/step - loss: 0.2968 - accuracy: 0.8798 - val_loss: 0.3841 - val_accuracy: 0.8433\n",
      "Epoch 2/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2969 - accuracy: 0.8783 - val_loss: 0.3838 - val_accuracy: 0.8433\n",
      "Epoch 3/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2969 - accuracy: 0.8798 - val_loss: 0.3845 - val_accuracy: 0.8433\n",
      "Epoch 4/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2969 - accuracy: 0.8783 - val_loss: 0.3845 - val_accuracy: 0.8419\n",
      "Epoch 5/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2969 - accuracy: 0.8798 - val_loss: 0.3845 - val_accuracy: 0.8404\n",
      "Epoch 6/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2968 - accuracy: 0.8783 - val_loss: 0.3844 - val_accuracy: 0.8389\n",
      "Epoch 7/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2967 - accuracy: 0.8798 - val_loss: 0.3845 - val_accuracy: 0.8389\n",
      "Epoch 8/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2968 - accuracy: 0.8798 - val_loss: 0.3840 - val_accuracy: 0.8419\n",
      "Epoch 9/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2968 - accuracy: 0.8798 - val_loss: 0.3846 - val_accuracy: 0.8419\n",
      "Epoch 10/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2969 - accuracy: 0.8812 - val_loss: 0.3843 - val_accuracy: 0.8419\n",
      "Epoch 11/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2968 - accuracy: 0.8798 - val_loss: 0.3841 - val_accuracy: 0.8404\n",
      "Epoch 12/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2967 - accuracy: 0.8798 - val_loss: 0.3838 - val_accuracy: 0.8404\n",
      "Epoch 13/300\n",
      "682/682 [==============================] - 0s 21us/step - loss: 0.2969 - accuracy: 0.8783 - val_loss: 0.3841 - val_accuracy: 0.8419\n",
      "Epoch 14/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2968 - accuracy: 0.8783 - val_loss: 0.3840 - val_accuracy: 0.8419\n",
      "Epoch 15/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2969 - accuracy: 0.8798 - val_loss: 0.3843 - val_accuracy: 0.8419\n",
      "Epoch 16/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2966 - accuracy: 0.8827 - val_loss: 0.3844 - val_accuracy: 0.8419\n",
      "Epoch 17/300\n",
      "682/682 [==============================] - 0s 23us/step - loss: 0.2967 - accuracy: 0.8827 - val_loss: 0.3846 - val_accuracy: 0.8389\n",
      "Epoch 18/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2967 - accuracy: 0.8812 - val_loss: 0.3842 - val_accuracy: 0.8419\n",
      "Epoch 19/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2968 - accuracy: 0.8812 - val_loss: 0.3842 - val_accuracy: 0.8404\n",
      "Epoch 20/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2966 - accuracy: 0.8827 - val_loss: 0.3842 - val_accuracy: 0.8404\n",
      "Epoch 21/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2966 - accuracy: 0.8812 - val_loss: 0.3843 - val_accuracy: 0.8419\n",
      "Epoch 22/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2966 - accuracy: 0.8798 - val_loss: 0.3839 - val_accuracy: 0.8404\n",
      "Epoch 23/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2966 - accuracy: 0.8798 - val_loss: 0.3837 - val_accuracy: 0.8419\n",
      "Epoch 24/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2966 - accuracy: 0.8798 - val_loss: 0.3833 - val_accuracy: 0.8419\n",
      "Epoch 25/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2966 - accuracy: 0.8783 - val_loss: 0.3834 - val_accuracy: 0.8419\n",
      "Epoch 26/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2966 - accuracy: 0.8783 - val_loss: 0.3833 - val_accuracy: 0.8419\n",
      "Epoch 27/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2965 - accuracy: 0.8798 - val_loss: 0.3829 - val_accuracy: 0.8419\n",
      "Epoch 28/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2967 - accuracy: 0.8783 - val_loss: 0.3828 - val_accuracy: 0.8433\n",
      "Epoch 29/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2967 - accuracy: 0.8798 - val_loss: 0.3829 - val_accuracy: 0.8419\n",
      "Epoch 30/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2965 - accuracy: 0.8783 - val_loss: 0.3831 - val_accuracy: 0.8419\n",
      "Epoch 31/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2966 - accuracy: 0.8812 - val_loss: 0.3828 - val_accuracy: 0.8433\n",
      "Epoch 32/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2966 - accuracy: 0.8798 - val_loss: 0.3834 - val_accuracy: 0.8419\n",
      "Epoch 33/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2967 - accuracy: 0.8783 - val_loss: 0.3839 - val_accuracy: 0.8419\n",
      "Epoch 34/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2964 - accuracy: 0.8798 - val_loss: 0.3839 - val_accuracy: 0.8419\n",
      "Epoch 35/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2966 - accuracy: 0.8798 - val_loss: 0.3839 - val_accuracy: 0.8433\n",
      "Epoch 36/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2965 - accuracy: 0.8798 - val_loss: 0.3840 - val_accuracy: 0.8433\n",
      "Epoch 37/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2965 - accuracy: 0.8812 - val_loss: 0.3842 - val_accuracy: 0.8419\n",
      "Epoch 38/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2965 - accuracy: 0.8812 - val_loss: 0.3843 - val_accuracy: 0.8419\n",
      "Epoch 39/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2966 - accuracy: 0.8798 - val_loss: 0.3844 - val_accuracy: 0.8419\n",
      "Epoch 40/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2964 - accuracy: 0.8812 - val_loss: 0.3844 - val_accuracy: 0.8419\n",
      "Epoch 41/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2965 - accuracy: 0.8812 - val_loss: 0.3845 - val_accuracy: 0.8419\n",
      "Epoch 42/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2963 - accuracy: 0.8827 - val_loss: 0.3844 - val_accuracy: 0.8433\n",
      "Epoch 43/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2964 - accuracy: 0.8812 - val_loss: 0.3848 - val_accuracy: 0.8433\n",
      "Epoch 44/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2964 - accuracy: 0.8827 - val_loss: 0.3848 - val_accuracy: 0.8433\n",
      "Epoch 45/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2963 - accuracy: 0.8827 - val_loss: 0.3844 - val_accuracy: 0.8448\n",
      "Epoch 46/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2964 - accuracy: 0.8827 - val_loss: 0.3846 - val_accuracy: 0.8433\n",
      "Epoch 47/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2964 - accuracy: 0.8812 - val_loss: 0.3848 - val_accuracy: 0.8404\n",
      "Epoch 48/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2964 - accuracy: 0.8827 - val_loss: 0.3852 - val_accuracy: 0.8404\n",
      "Epoch 49/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2964 - accuracy: 0.8812 - val_loss: 0.3853 - val_accuracy: 0.8389\n",
      "Epoch 50/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2963 - accuracy: 0.8812 - val_loss: 0.3853 - val_accuracy: 0.8404\n",
      "Epoch 51/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2963 - accuracy: 0.8812 - val_loss: 0.3853 - val_accuracy: 0.8389\n",
      "Epoch 52/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2963 - accuracy: 0.8827 - val_loss: 0.3856 - val_accuracy: 0.8404\n",
      "Epoch 53/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2962 - accuracy: 0.8812 - val_loss: 0.3856 - val_accuracy: 0.8419\n",
      "Epoch 54/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2963 - accuracy: 0.8827 - val_loss: 0.3857 - val_accuracy: 0.8389\n",
      "Epoch 55/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2963 - accuracy: 0.8827 - val_loss: 0.3859 - val_accuracy: 0.8389\n",
      "Epoch 56/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2963 - accuracy: 0.8842 - val_loss: 0.3852 - val_accuracy: 0.8404\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682/682 [==============================] - 0s 17us/step - loss: 0.2962 - accuracy: 0.8827 - val_loss: 0.3851 - val_accuracy: 0.8404\n",
      "Epoch 58/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2964 - accuracy: 0.8812 - val_loss: 0.3849 - val_accuracy: 0.8404\n",
      "Epoch 59/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2963 - accuracy: 0.8812 - val_loss: 0.3848 - val_accuracy: 0.8419\n",
      "Epoch 60/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2962 - accuracy: 0.8812 - val_loss: 0.3850 - val_accuracy: 0.8404\n",
      "Epoch 61/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2963 - accuracy: 0.8812 - val_loss: 0.3851 - val_accuracy: 0.8404\n",
      "Epoch 62/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2962 - accuracy: 0.8812 - val_loss: 0.3849 - val_accuracy: 0.8404\n",
      "Epoch 63/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2963 - accuracy: 0.8812 - val_loss: 0.3851 - val_accuracy: 0.8404\n",
      "Epoch 64/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2962 - accuracy: 0.8812 - val_loss: 0.3849 - val_accuracy: 0.8419\n",
      "Epoch 65/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2962 - accuracy: 0.8812 - val_loss: 0.3851 - val_accuracy: 0.8404\n",
      "Epoch 66/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2962 - accuracy: 0.8812 - val_loss: 0.3847 - val_accuracy: 0.8404\n",
      "Epoch 67/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2962 - accuracy: 0.8812 - val_loss: 0.3846 - val_accuracy: 0.8404\n",
      "Epoch 68/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2962 - accuracy: 0.8812 - val_loss: 0.3845 - val_accuracy: 0.8404\n",
      "Epoch 69/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2963 - accuracy: 0.8812 - val_loss: 0.3846 - val_accuracy: 0.8404\n",
      "Epoch 70/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2961 - accuracy: 0.8812 - val_loss: 0.3846 - val_accuracy: 0.8404\n",
      "Epoch 71/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2963 - accuracy: 0.8812 - val_loss: 0.3844 - val_accuracy: 0.8404\n",
      "Epoch 72/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2962 - accuracy: 0.8827 - val_loss: 0.3847 - val_accuracy: 0.8419\n",
      "Epoch 73/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2964 - accuracy: 0.8812 - val_loss: 0.3846 - val_accuracy: 0.8389\n",
      "Epoch 74/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2960 - accuracy: 0.8827 - val_loss: 0.3843 - val_accuracy: 0.8419\n",
      "Epoch 75/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2961 - accuracy: 0.8827 - val_loss: 0.3843 - val_accuracy: 0.8389\n",
      "Epoch 76/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2961 - accuracy: 0.8812 - val_loss: 0.3845 - val_accuracy: 0.8389\n",
      "Epoch 77/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2962 - accuracy: 0.8812 - val_loss: 0.3849 - val_accuracy: 0.8389\n",
      "Epoch 78/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2962 - accuracy: 0.8827 - val_loss: 0.3850 - val_accuracy: 0.8389\n",
      "Epoch 79/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2961 - accuracy: 0.8812 - val_loss: 0.3850 - val_accuracy: 0.8389\n",
      "Epoch 80/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2961 - accuracy: 0.8812 - val_loss: 0.3851 - val_accuracy: 0.8389\n",
      "Epoch 81/300\n",
      "682/682 [==============================] - 0s 22us/step - loss: 0.2960 - accuracy: 0.8812 - val_loss: 0.3854 - val_accuracy: 0.8375\n",
      "Epoch 82/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2961 - accuracy: 0.8842 - val_loss: 0.3859 - val_accuracy: 0.8389\n",
      "Epoch 83/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2960 - accuracy: 0.8842 - val_loss: 0.3859 - val_accuracy: 0.8375\n",
      "Epoch 84/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2960 - accuracy: 0.8827 - val_loss: 0.3857 - val_accuracy: 0.8375\n",
      "Epoch 85/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2961 - accuracy: 0.8827 - val_loss: 0.3857 - val_accuracy: 0.8389\n",
      "Epoch 86/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2959 - accuracy: 0.8842 - val_loss: 0.3854 - val_accuracy: 0.8375\n",
      "Epoch 87/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2961 - accuracy: 0.8827 - val_loss: 0.3853 - val_accuracy: 0.8375\n",
      "Epoch 88/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2960 - accuracy: 0.8827 - val_loss: 0.3849 - val_accuracy: 0.8375\n",
      "Epoch 89/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2959 - accuracy: 0.8812 - val_loss: 0.3845 - val_accuracy: 0.8389\n",
      "Epoch 90/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2959 - accuracy: 0.8827 - val_loss: 0.3838 - val_accuracy: 0.8433\n",
      "Epoch 91/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2960 - accuracy: 0.8812 - val_loss: 0.3839 - val_accuracy: 0.8433\n",
      "Epoch 92/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2960 - accuracy: 0.8798 - val_loss: 0.3842 - val_accuracy: 0.8404\n",
      "Epoch 93/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2960 - accuracy: 0.8798 - val_loss: 0.3846 - val_accuracy: 0.8389\n",
      "Epoch 94/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2960 - accuracy: 0.8798 - val_loss: 0.3850 - val_accuracy: 0.8360\n",
      "Epoch 95/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2959 - accuracy: 0.8827 - val_loss: 0.3845 - val_accuracy: 0.8404\n",
      "Epoch 96/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2959 - accuracy: 0.8798 - val_loss: 0.3843 - val_accuracy: 0.8419\n",
      "Epoch 97/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2959 - accuracy: 0.8827 - val_loss: 0.3839 - val_accuracy: 0.8419\n",
      "Epoch 98/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2960 - accuracy: 0.8798 - val_loss: 0.3839 - val_accuracy: 0.8419\n",
      "Epoch 99/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2959 - accuracy: 0.8798 - val_loss: 0.3837 - val_accuracy: 0.8419\n",
      "Epoch 100/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2960 - accuracy: 0.8798 - val_loss: 0.3838 - val_accuracy: 0.8404\n",
      "Epoch 101/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2959 - accuracy: 0.8798 - val_loss: 0.3843 - val_accuracy: 0.8404\n",
      "Epoch 102/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2958 - accuracy: 0.8798 - val_loss: 0.3842 - val_accuracy: 0.8404\n",
      "Epoch 103/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2960 - accuracy: 0.8798 - val_loss: 0.3848 - val_accuracy: 0.8375\n",
      "Epoch 104/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2959 - accuracy: 0.8827 - val_loss: 0.3843 - val_accuracy: 0.8404\n",
      "Epoch 105/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2958 - accuracy: 0.8812 - val_loss: 0.3845 - val_accuracy: 0.8389\n",
      "Epoch 106/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2958 - accuracy: 0.8827 - val_loss: 0.3847 - val_accuracy: 0.8389\n",
      "Epoch 107/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2959 - accuracy: 0.8827 - val_loss: 0.3849 - val_accuracy: 0.8404\n",
      "Epoch 108/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2959 - accuracy: 0.8827 - val_loss: 0.3848 - val_accuracy: 0.8375\n",
      "Epoch 109/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2958 - accuracy: 0.8827 - val_loss: 0.3847 - val_accuracy: 0.8389\n",
      "Epoch 110/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2958 - accuracy: 0.8827 - val_loss: 0.3845 - val_accuracy: 0.8404\n",
      "Epoch 111/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2958 - accuracy: 0.8812 - val_loss: 0.3842 - val_accuracy: 0.8419\n",
      "Epoch 112/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2958 - accuracy: 0.8812 - val_loss: 0.3848 - val_accuracy: 0.8389\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682/682 [==============================] - 0s 16us/step - loss: 0.2959 - accuracy: 0.8842 - val_loss: 0.3848 - val_accuracy: 0.8419\n",
      "Epoch 114/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2957 - accuracy: 0.8827 - val_loss: 0.3848 - val_accuracy: 0.8404\n",
      "Epoch 115/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2959 - accuracy: 0.8827 - val_loss: 0.3849 - val_accuracy: 0.8389\n",
      "Epoch 116/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2958 - accuracy: 0.8827 - val_loss: 0.3850 - val_accuracy: 0.8404\n",
      "Epoch 117/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2958 - accuracy: 0.8827 - val_loss: 0.3853 - val_accuracy: 0.8389\n",
      "Epoch 118/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2958 - accuracy: 0.8812 - val_loss: 0.3856 - val_accuracy: 0.8389\n",
      "Epoch 119/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2959 - accuracy: 0.8827 - val_loss: 0.3849 - val_accuracy: 0.8404\n",
      "Epoch 120/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2957 - accuracy: 0.8842 - val_loss: 0.3843 - val_accuracy: 0.8389\n",
      "Epoch 121/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2958 - accuracy: 0.8827 - val_loss: 0.3845 - val_accuracy: 0.8404\n",
      "Epoch 122/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2957 - accuracy: 0.8827 - val_loss: 0.3846 - val_accuracy: 0.8404\n",
      "Epoch 123/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2957 - accuracy: 0.8827 - val_loss: 0.3843 - val_accuracy: 0.8404\n",
      "Epoch 124/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2958 - accuracy: 0.8842 - val_loss: 0.3838 - val_accuracy: 0.8404\n",
      "Epoch 125/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2957 - accuracy: 0.8827 - val_loss: 0.3834 - val_accuracy: 0.8404\n",
      "Epoch 126/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2957 - accuracy: 0.8827 - val_loss: 0.3832 - val_accuracy: 0.8419\n",
      "Epoch 127/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2957 - accuracy: 0.8798 - val_loss: 0.3831 - val_accuracy: 0.8419\n",
      "Epoch 128/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2957 - accuracy: 0.8798 - val_loss: 0.3831 - val_accuracy: 0.8419\n",
      "Epoch 129/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2956 - accuracy: 0.8812 - val_loss: 0.3829 - val_accuracy: 0.8433\n",
      "Epoch 130/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2959 - accuracy: 0.8798 - val_loss: 0.3832 - val_accuracy: 0.8433\n",
      "Epoch 131/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2956 - accuracy: 0.8798 - val_loss: 0.3835 - val_accuracy: 0.8433\n",
      "Epoch 132/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2957 - accuracy: 0.8812 - val_loss: 0.3834 - val_accuracy: 0.8433\n",
      "Epoch 133/300\n",
      "682/682 [==============================] - 0s 21us/step - loss: 0.2956 - accuracy: 0.8827 - val_loss: 0.3830 - val_accuracy: 0.8433\n",
      "Epoch 134/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2957 - accuracy: 0.8798 - val_loss: 0.3834 - val_accuracy: 0.8448\n",
      "Epoch 135/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2957 - accuracy: 0.8798 - val_loss: 0.3835 - val_accuracy: 0.8448\n",
      "Epoch 136/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2956 - accuracy: 0.8798 - val_loss: 0.3834 - val_accuracy: 0.8448\n",
      "Epoch 137/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2956 - accuracy: 0.8798 - val_loss: 0.3829 - val_accuracy: 0.8448\n",
      "Epoch 138/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2957 - accuracy: 0.8798 - val_loss: 0.3825 - val_accuracy: 0.8463\n",
      "Epoch 139/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2957 - accuracy: 0.8812 - val_loss: 0.3828 - val_accuracy: 0.8448\n",
      "Epoch 140/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2956 - accuracy: 0.8798 - val_loss: 0.3826 - val_accuracy: 0.8448\n",
      "Epoch 141/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2956 - accuracy: 0.8798 - val_loss: 0.3828 - val_accuracy: 0.8448\n",
      "Epoch 142/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2957 - accuracy: 0.8812 - val_loss: 0.3831 - val_accuracy: 0.8448\n",
      "Epoch 143/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2955 - accuracy: 0.8798 - val_loss: 0.3830 - val_accuracy: 0.8448\n",
      "Epoch 144/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2956 - accuracy: 0.8798 - val_loss: 0.3832 - val_accuracy: 0.8448\n",
      "Epoch 145/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2956 - accuracy: 0.8798 - val_loss: 0.3833 - val_accuracy: 0.8448\n",
      "Epoch 146/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2955 - accuracy: 0.8812 - val_loss: 0.3832 - val_accuracy: 0.8433\n",
      "Epoch 147/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2957 - accuracy: 0.8798 - val_loss: 0.3834 - val_accuracy: 0.8419\n",
      "Epoch 148/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2957 - accuracy: 0.8812 - val_loss: 0.3833 - val_accuracy: 0.8419\n",
      "Epoch 149/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2955 - accuracy: 0.8812 - val_loss: 0.3833 - val_accuracy: 0.8389\n",
      "Epoch 150/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2956 - accuracy: 0.8827 - val_loss: 0.3830 - val_accuracy: 0.8419\n",
      "Epoch 151/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2956 - accuracy: 0.8783 - val_loss: 0.3830 - val_accuracy: 0.8433\n",
      "Epoch 152/300\n",
      "682/682 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.89 - 0s 16us/step - loss: 0.2957 - accuracy: 0.8798 - val_loss: 0.3833 - val_accuracy: 0.8433\n",
      "Epoch 153/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2955 - accuracy: 0.8842 - val_loss: 0.3829 - val_accuracy: 0.8448\n",
      "Epoch 154/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2955 - accuracy: 0.8798 - val_loss: 0.3832 - val_accuracy: 0.8433\n",
      "Epoch 155/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2956 - accuracy: 0.8812 - val_loss: 0.3837 - val_accuracy: 0.8404\n",
      "Epoch 156/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2956 - accuracy: 0.8827 - val_loss: 0.3835 - val_accuracy: 0.8419\n",
      "Epoch 157/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2956 - accuracy: 0.8827 - val_loss: 0.3837 - val_accuracy: 0.8389\n",
      "Epoch 158/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2955 - accuracy: 0.8842 - val_loss: 0.3833 - val_accuracy: 0.8419\n",
      "Epoch 159/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2956 - accuracy: 0.8827 - val_loss: 0.3836 - val_accuracy: 0.8419\n",
      "Epoch 160/300\n",
      "682/682 [==============================] - 0s 22us/step - loss: 0.2955 - accuracy: 0.8827 - val_loss: 0.3841 - val_accuracy: 0.8404\n",
      "Epoch 161/300\n",
      "682/682 [==============================] - 0s 23us/step - loss: 0.2955 - accuracy: 0.8842 - val_loss: 0.3842 - val_accuracy: 0.8389\n",
      "Epoch 162/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2954 - accuracy: 0.8827 - val_loss: 0.3840 - val_accuracy: 0.8375\n",
      "Epoch 163/300\n",
      "682/682 [==============================] - 0s 22us/step - loss: 0.2955 - accuracy: 0.8842 - val_loss: 0.3838 - val_accuracy: 0.8389\n",
      "Epoch 164/300\n",
      "682/682 [==============================] - 0s 22us/step - loss: 0.2955 - accuracy: 0.8842 - val_loss: 0.3838 - val_accuracy: 0.8389\n",
      "Epoch 165/300\n",
      "682/682 [==============================] - 0s 24us/step - loss: 0.2955 - accuracy: 0.8827 - val_loss: 0.3834 - val_accuracy: 0.8404\n",
      "Epoch 166/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2955 - accuracy: 0.8827 - val_loss: 0.3833 - val_accuracy: 0.8404\n",
      "Epoch 167/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2955 - accuracy: 0.8812 - val_loss: 0.3834 - val_accuracy: 0.8389\n",
      "Epoch 168/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2955 - accuracy: 0.8812 - val_loss: 0.3829 - val_accuracy: 0.8404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/300\n",
      "682/682 [==============================] - 0s 21us/step - loss: 0.2955 - accuracy: 0.8798 - val_loss: 0.3826 - val_accuracy: 0.8448\n",
      "Epoch 170/300\n",
      "682/682 [==============================] - 0s 21us/step - loss: 0.2955 - accuracy: 0.8798 - val_loss: 0.3826 - val_accuracy: 0.8433\n",
      "Epoch 171/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2954 - accuracy: 0.8798 - val_loss: 0.3827 - val_accuracy: 0.8448\n",
      "Epoch 172/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2954 - accuracy: 0.8798 - val_loss: 0.3827 - val_accuracy: 0.8433\n",
      "Epoch 173/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2955 - accuracy: 0.8783 - val_loss: 0.3829 - val_accuracy: 0.8433\n",
      "Epoch 174/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2955 - accuracy: 0.8798 - val_loss: 0.3831 - val_accuracy: 0.8419\n",
      "Epoch 175/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2955 - accuracy: 0.8827 - val_loss: 0.3832 - val_accuracy: 0.8419\n",
      "Epoch 176/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2954 - accuracy: 0.8798 - val_loss: 0.3826 - val_accuracy: 0.8448\n",
      "Epoch 177/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2955 - accuracy: 0.8798 - val_loss: 0.3830 - val_accuracy: 0.8448\n",
      "Epoch 178/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2954 - accuracy: 0.8798 - val_loss: 0.3830 - val_accuracy: 0.8448\n",
      "Epoch 179/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2954 - accuracy: 0.8798 - val_loss: 0.3829 - val_accuracy: 0.8433\n",
      "Epoch 180/300\n",
      "682/682 [==============================] - 0s 21us/step - loss: 0.2955 - accuracy: 0.8798 - val_loss: 0.3832 - val_accuracy: 0.8463\n",
      "Epoch 181/300\n",
      "682/682 [==============================] - 0s 22us/step - loss: 0.2953 - accuracy: 0.8798 - val_loss: 0.3833 - val_accuracy: 0.8463\n",
      "Epoch 182/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2954 - accuracy: 0.8798 - val_loss: 0.3833 - val_accuracy: 0.8463\n",
      "Epoch 183/300\n",
      "682/682 [==============================] - ETA: 0s - loss: 0.2338 - accuracy: 0.91 - 0s 17us/step - loss: 0.2954 - accuracy: 0.8798 - val_loss: 0.3833 - val_accuracy: 0.8463\n",
      "Epoch 184/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2953 - accuracy: 0.8798 - val_loss: 0.3833 - val_accuracy: 0.8463\n",
      "Epoch 185/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2954 - accuracy: 0.8812 - val_loss: 0.3835 - val_accuracy: 0.8433\n",
      "Epoch 186/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2954 - accuracy: 0.8812 - val_loss: 0.3831 - val_accuracy: 0.8463\n",
      "Epoch 187/300\n",
      "682/682 [==============================] - 0s 21us/step - loss: 0.2953 - accuracy: 0.8798 - val_loss: 0.3836 - val_accuracy: 0.8448\n",
      "Epoch 188/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2954 - accuracy: 0.8812 - val_loss: 0.3830 - val_accuracy: 0.8463\n",
      "Epoch 189/300\n",
      "682/682 [==============================] - ETA: 0s - loss: 0.3424 - accuracy: 0.86 - 0s 21us/step - loss: 0.2954 - accuracy: 0.8812 - val_loss: 0.3830 - val_accuracy: 0.8463\n",
      "Epoch 190/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2953 - accuracy: 0.8798 - val_loss: 0.3833 - val_accuracy: 0.8463\n",
      "Epoch 191/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2954 - accuracy: 0.8783 - val_loss: 0.3831 - val_accuracy: 0.8463\n",
      "Epoch 192/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2953 - accuracy: 0.8812 - val_loss: 0.3829 - val_accuracy: 0.8463\n",
      "Epoch 193/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2955 - accuracy: 0.8798 - val_loss: 0.3832 - val_accuracy: 0.8463\n",
      "Epoch 194/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2952 - accuracy: 0.8798 - val_loss: 0.3835 - val_accuracy: 0.8448\n",
      "Epoch 195/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2954 - accuracy: 0.8812 - val_loss: 0.3833 - val_accuracy: 0.8463\n",
      "Epoch 196/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2952 - accuracy: 0.8783 - val_loss: 0.3837 - val_accuracy: 0.8433\n",
      "Epoch 197/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2953 - accuracy: 0.8827 - val_loss: 0.3836 - val_accuracy: 0.8433\n",
      "Epoch 198/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2953 - accuracy: 0.8798 - val_loss: 0.3836 - val_accuracy: 0.8419\n",
      "Epoch 199/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2953 - accuracy: 0.8842 - val_loss: 0.3835 - val_accuracy: 0.8433\n",
      "Epoch 200/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2953 - accuracy: 0.8827 - val_loss: 0.3832 - val_accuracy: 0.8433\n",
      "Epoch 201/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2952 - accuracy: 0.8812 - val_loss: 0.3832 - val_accuracy: 0.8433\n",
      "Epoch 202/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2953 - accuracy: 0.8827 - val_loss: 0.3835 - val_accuracy: 0.8433\n",
      "Epoch 203/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2953 - accuracy: 0.8827 - val_loss: 0.3838 - val_accuracy: 0.8433\n",
      "Epoch 204/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2952 - accuracy: 0.8842 - val_loss: 0.3841 - val_accuracy: 0.8433\n",
      "Epoch 205/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2952 - accuracy: 0.8856 - val_loss: 0.3845 - val_accuracy: 0.8419\n",
      "Epoch 206/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2954 - accuracy: 0.8842 - val_loss: 0.3848 - val_accuracy: 0.8419\n",
      "Epoch 207/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2953 - accuracy: 0.8842 - val_loss: 0.3839 - val_accuracy: 0.8448\n",
      "Epoch 208/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2953 - accuracy: 0.8871 - val_loss: 0.3837 - val_accuracy: 0.8448\n",
      "Epoch 209/300\n",
      "682/682 [==============================] - 0s 23us/step - loss: 0.2953 - accuracy: 0.8856 - val_loss: 0.3839 - val_accuracy: 0.8448\n",
      "Epoch 210/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2952 - accuracy: 0.8856 - val_loss: 0.3846 - val_accuracy: 0.8433\n",
      "Epoch 211/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2951 - accuracy: 0.8871 - val_loss: 0.3845 - val_accuracy: 0.8433\n",
      "Epoch 212/300\n",
      "682/682 [==============================] - 0s 21us/step - loss: 0.2951 - accuracy: 0.8871 - val_loss: 0.3845 - val_accuracy: 0.8433\n",
      "Epoch 213/300\n",
      "682/682 [==============================] - 0s 22us/step - loss: 0.2952 - accuracy: 0.8871 - val_loss: 0.3843 - val_accuracy: 0.8419\n",
      "Epoch 214/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2952 - accuracy: 0.8871 - val_loss: 0.3844 - val_accuracy: 0.8433\n",
      "Epoch 215/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2953 - accuracy: 0.8871 - val_loss: 0.3843 - val_accuracy: 0.8433\n",
      "Epoch 216/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2952 - accuracy: 0.8871 - val_loss: 0.3842 - val_accuracy: 0.8433\n",
      "Epoch 217/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2952 - accuracy: 0.8856 - val_loss: 0.3844 - val_accuracy: 0.8448\n",
      "Epoch 218/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2952 - accuracy: 0.8856 - val_loss: 0.3848 - val_accuracy: 0.8419\n",
      "Epoch 219/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2952 - accuracy: 0.8856 - val_loss: 0.3842 - val_accuracy: 0.8433\n",
      "Epoch 220/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2952 - accuracy: 0.8842 - val_loss: 0.3838 - val_accuracy: 0.8433\n",
      "Epoch 221/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2951 - accuracy: 0.8856 - val_loss: 0.3834 - val_accuracy: 0.8433\n",
      "Epoch 222/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2951 - accuracy: 0.8856 - val_loss: 0.3837 - val_accuracy: 0.8433\n",
      "Epoch 223/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2953 - accuracy: 0.8856 - val_loss: 0.3839 - val_accuracy: 0.8448\n",
      "Epoch 224/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682/682 [==============================] - 0s 18us/step - loss: 0.2951 - accuracy: 0.8856 - val_loss: 0.3837 - val_accuracy: 0.8448\n",
      "Epoch 225/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2952 - accuracy: 0.8856 - val_loss: 0.3839 - val_accuracy: 0.8463\n",
      "Epoch 226/300\n",
      "682/682 [==============================] - ETA: 0s - loss: 0.3122 - accuracy: 0.88 - 0s 23us/step - loss: 0.2951 - accuracy: 0.8842 - val_loss: 0.3842 - val_accuracy: 0.8463\n",
      "Epoch 227/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2950 - accuracy: 0.8842 - val_loss: 0.3840 - val_accuracy: 0.8448\n",
      "Epoch 228/300\n",
      "682/682 [==============================] - 0s 21us/step - loss: 0.2951 - accuracy: 0.8842 - val_loss: 0.3840 - val_accuracy: 0.8448\n",
      "Epoch 229/300\n",
      "682/682 [==============================] - 0s 21us/step - loss: 0.2953 - accuracy: 0.8827 - val_loss: 0.3834 - val_accuracy: 0.8433\n",
      "Epoch 230/300\n",
      "682/682 [==============================] - 0s 21us/step - loss: 0.2951 - accuracy: 0.8827 - val_loss: 0.3833 - val_accuracy: 0.8433\n",
      "Epoch 231/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2951 - accuracy: 0.8827 - val_loss: 0.3831 - val_accuracy: 0.8433\n",
      "Epoch 232/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2950 - accuracy: 0.8827 - val_loss: 0.3832 - val_accuracy: 0.8448\n",
      "Epoch 233/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2952 - accuracy: 0.8842 - val_loss: 0.3832 - val_accuracy: 0.8448\n",
      "Epoch 234/300\n",
      "682/682 [==============================] - 0s 22us/step - loss: 0.2952 - accuracy: 0.8842 - val_loss: 0.3833 - val_accuracy: 0.8448\n",
      "Epoch 235/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2952 - accuracy: 0.8842 - val_loss: 0.3834 - val_accuracy: 0.8448\n",
      "Epoch 236/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2951 - accuracy: 0.8842 - val_loss: 0.3833 - val_accuracy: 0.8448\n",
      "Epoch 237/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2951 - accuracy: 0.8842 - val_loss: 0.3832 - val_accuracy: 0.8448\n",
      "Epoch 238/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2952 - accuracy: 0.8842 - val_loss: 0.3836 - val_accuracy: 0.8448\n",
      "Epoch 239/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2950 - accuracy: 0.8827 - val_loss: 0.3830 - val_accuracy: 0.8448\n",
      "Epoch 240/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2951 - accuracy: 0.8842 - val_loss: 0.3831 - val_accuracy: 0.8448\n",
      "Epoch 241/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2949 - accuracy: 0.8842 - val_loss: 0.3832 - val_accuracy: 0.8448\n",
      "Epoch 242/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2950 - accuracy: 0.8842 - val_loss: 0.3834 - val_accuracy: 0.8463\n",
      "Epoch 243/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2951 - accuracy: 0.8842 - val_loss: 0.3835 - val_accuracy: 0.8448\n",
      "Epoch 244/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2950 - accuracy: 0.8842 - val_loss: 0.3834 - val_accuracy: 0.8463\n",
      "Epoch 245/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2950 - accuracy: 0.8827 - val_loss: 0.3837 - val_accuracy: 0.8448\n",
      "Epoch 246/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2950 - accuracy: 0.8842 - val_loss: 0.3838 - val_accuracy: 0.8448\n",
      "Epoch 247/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2949 - accuracy: 0.8842 - val_loss: 0.3833 - val_accuracy: 0.8463\n",
      "Epoch 248/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2949 - accuracy: 0.8842 - val_loss: 0.3835 - val_accuracy: 0.8463\n",
      "Epoch 249/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2950 - accuracy: 0.8842 - val_loss: 0.3838 - val_accuracy: 0.8463\n",
      "Epoch 250/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2951 - accuracy: 0.8842 - val_loss: 0.3841 - val_accuracy: 0.8463\n",
      "Epoch 251/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2950 - accuracy: 0.8856 - val_loss: 0.3842 - val_accuracy: 0.8463\n",
      "Epoch 252/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2950 - accuracy: 0.8842 - val_loss: 0.3838 - val_accuracy: 0.8463\n",
      "Epoch 253/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2949 - accuracy: 0.8842 - val_loss: 0.3840 - val_accuracy: 0.8463\n",
      "Epoch 254/300\n",
      "682/682 [==============================] - 0s 22us/step - loss: 0.2949 - accuracy: 0.8842 - val_loss: 0.3834 - val_accuracy: 0.8463\n",
      "Epoch 255/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2952 - accuracy: 0.8827 - val_loss: 0.3834 - val_accuracy: 0.8463\n",
      "Epoch 256/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2949 - accuracy: 0.8842 - val_loss: 0.3832 - val_accuracy: 0.8463\n",
      "Epoch 257/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2949 - accuracy: 0.8842 - val_loss: 0.3829 - val_accuracy: 0.8463\n",
      "Epoch 258/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2949 - accuracy: 0.8856 - val_loss: 0.3832 - val_accuracy: 0.8463\n",
      "Epoch 259/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2949 - accuracy: 0.8856 - val_loss: 0.3832 - val_accuracy: 0.8463\n",
      "Epoch 260/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2949 - accuracy: 0.8856 - val_loss: 0.3831 - val_accuracy: 0.8463\n",
      "Epoch 261/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2949 - accuracy: 0.8856 - val_loss: 0.3831 - val_accuracy: 0.8448\n",
      "Epoch 262/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2950 - accuracy: 0.8856 - val_loss: 0.3831 - val_accuracy: 0.8448\n",
      "Epoch 263/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2950 - accuracy: 0.8842 - val_loss: 0.3832 - val_accuracy: 0.8448\n",
      "Epoch 264/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2949 - accuracy: 0.8856 - val_loss: 0.3831 - val_accuracy: 0.8448\n",
      "Epoch 265/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2948 - accuracy: 0.8842 - val_loss: 0.3833 - val_accuracy: 0.8433\n",
      "Epoch 266/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2952 - accuracy: 0.8842 - val_loss: 0.3829 - val_accuracy: 0.8433\n",
      "Epoch 267/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2949 - accuracy: 0.8856 - val_loss: 0.3831 - val_accuracy: 0.8433\n",
      "Epoch 268/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2949 - accuracy: 0.8856 - val_loss: 0.3829 - val_accuracy: 0.8433\n",
      "Epoch 269/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2949 - accuracy: 0.8856 - val_loss: 0.3828 - val_accuracy: 0.8433\n",
      "Epoch 270/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2948 - accuracy: 0.8842 - val_loss: 0.3830 - val_accuracy: 0.8433\n",
      "Epoch 271/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2950 - accuracy: 0.8871 - val_loss: 0.3830 - val_accuracy: 0.8448\n",
      "Epoch 272/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2949 - accuracy: 0.8842 - val_loss: 0.3829 - val_accuracy: 0.8433\n",
      "Epoch 273/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2950 - accuracy: 0.8842 - val_loss: 0.3827 - val_accuracy: 0.8433\n",
      "Epoch 274/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2948 - accuracy: 0.8842 - val_loss: 0.3830 - val_accuracy: 0.8433\n",
      "Epoch 275/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2949 - accuracy: 0.8856 - val_loss: 0.3831 - val_accuracy: 0.8433\n",
      "Epoch 276/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2948 - accuracy: 0.8842 - val_loss: 0.3832 - val_accuracy: 0.8433\n",
      "Epoch 277/300\n",
      "682/682 [==============================] - 0s 21us/step - loss: 0.2948 - accuracy: 0.8842 - val_loss: 0.3827 - val_accuracy: 0.8433\n",
      "Epoch 278/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2948 - accuracy: 0.8827 - val_loss: 0.3829 - val_accuracy: 0.8433\n",
      "Epoch 279/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2949 - accuracy: 0.8827 - val_loss: 0.3829 - val_accuracy: 0.8433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2948 - accuracy: 0.8827 - val_loss: 0.3831 - val_accuracy: 0.8419\n",
      "Epoch 281/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2947 - accuracy: 0.8827 - val_loss: 0.3829 - val_accuracy: 0.8433\n",
      "Epoch 282/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2947 - accuracy: 0.8842 - val_loss: 0.3829 - val_accuracy: 0.8433\n",
      "Epoch 283/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2949 - accuracy: 0.8827 - val_loss: 0.3829 - val_accuracy: 0.8433\n",
      "Epoch 284/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2948 - accuracy: 0.8842 - val_loss: 0.3826 - val_accuracy: 0.8448\n",
      "Epoch 285/300\n",
      "682/682 [==============================] - 0s 19us/step - loss: 0.2949 - accuracy: 0.8842 - val_loss: 0.3826 - val_accuracy: 0.8448\n",
      "Epoch 286/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2948 - accuracy: 0.8842 - val_loss: 0.3821 - val_accuracy: 0.8448\n",
      "Epoch 287/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2949 - accuracy: 0.8827 - val_loss: 0.3820 - val_accuracy: 0.8477\n",
      "Epoch 288/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2948 - accuracy: 0.8798 - val_loss: 0.3821 - val_accuracy: 0.8477\n",
      "Epoch 289/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2948 - accuracy: 0.8812 - val_loss: 0.3824 - val_accuracy: 0.8463\n",
      "Epoch 290/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2949 - accuracy: 0.8827 - val_loss: 0.3825 - val_accuracy: 0.8477\n",
      "Epoch 291/300\n",
      "682/682 [==============================] - ETA: 0s - loss: 0.3770 - accuracy: 0.84 - 0s 16us/step - loss: 0.2948 - accuracy: 0.8812 - val_loss: 0.3828 - val_accuracy: 0.8477\n",
      "Epoch 292/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2949 - accuracy: 0.8827 - val_loss: 0.3821 - val_accuracy: 0.8463\n",
      "Epoch 293/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2949 - accuracy: 0.8827 - val_loss: 0.3819 - val_accuracy: 0.8463\n",
      "Epoch 294/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2948 - accuracy: 0.8827 - val_loss: 0.3816 - val_accuracy: 0.8463\n",
      "Epoch 295/300\n",
      "682/682 [==============================] - 0s 20us/step - loss: 0.2948 - accuracy: 0.8827 - val_loss: 0.3818 - val_accuracy: 0.8463\n",
      "Epoch 296/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2949 - accuracy: 0.8827 - val_loss: 0.3810 - val_accuracy: 0.8433\n",
      "Epoch 297/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2949 - accuracy: 0.8812 - val_loss: 0.3809 - val_accuracy: 0.8433\n",
      "Epoch 298/300\n",
      "682/682 [==============================] - 0s 16us/step - loss: 0.2949 - accuracy: 0.8812 - val_loss: 0.3814 - val_accuracy: 0.8463\n",
      "Epoch 299/300\n",
      "682/682 [==============================] - 0s 18us/step - loss: 0.2947 - accuracy: 0.8812 - val_loss: 0.3815 - val_accuracy: 0.8463\n",
      "Epoch 300/300\n",
      "682/682 [==============================] - 0s 17us/step - loss: 0.2948 - accuracy: 0.8812 - val_loss: 0.3816 - val_accuracy: 0.8463\n",
      "Train on 967 samples, validate on 967 samples\n",
      "Epoch 1/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3448 - accuracy: 0.8511 - val_loss: 0.3664 - val_accuracy: 0.8552\n",
      "Epoch 2/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3417 - accuracy: 0.8511 - val_loss: 0.3639 - val_accuracy: 0.8573\n",
      "Epoch 3/300\n",
      "967/967 [==============================] - ETA: 0s - loss: 0.3403 - accuracy: 0.85 - 0s 17us/step - loss: 0.3393 - accuracy: 0.8552 - val_loss: 0.3617 - val_accuracy: 0.8583\n",
      "Epoch 4/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3367 - accuracy: 0.8532 - val_loss: 0.3599 - val_accuracy: 0.8604\n",
      "Epoch 5/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3347 - accuracy: 0.8552 - val_loss: 0.3583 - val_accuracy: 0.8604\n",
      "Epoch 6/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3331 - accuracy: 0.8552 - val_loss: 0.3570 - val_accuracy: 0.8604\n",
      "Epoch 7/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3313 - accuracy: 0.8552 - val_loss: 0.3557 - val_accuracy: 0.8635\n",
      "Epoch 8/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3298 - accuracy: 0.8573 - val_loss: 0.3547 - val_accuracy: 0.8614\n",
      "Epoch 9/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3284 - accuracy: 0.8583 - val_loss: 0.3537 - val_accuracy: 0.8614\n",
      "Epoch 10/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3272 - accuracy: 0.8604 - val_loss: 0.3528 - val_accuracy: 0.8594\n",
      "Epoch 11/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3258 - accuracy: 0.8594 - val_loss: 0.3522 - val_accuracy: 0.8604\n",
      "Epoch 12/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3247 - accuracy: 0.8614 - val_loss: 0.3515 - val_accuracy: 0.8604\n",
      "Epoch 13/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3237 - accuracy: 0.8594 - val_loss: 0.3508 - val_accuracy: 0.8573\n",
      "Epoch 14/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3228 - accuracy: 0.8604 - val_loss: 0.3505 - val_accuracy: 0.8573\n",
      "Epoch 15/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3220 - accuracy: 0.8604 - val_loss: 0.3500 - val_accuracy: 0.8594\n",
      "Epoch 16/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3211 - accuracy: 0.8594 - val_loss: 0.3495 - val_accuracy: 0.8594\n",
      "Epoch 17/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3203 - accuracy: 0.8604 - val_loss: 0.3491 - val_accuracy: 0.8594\n",
      "Epoch 18/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3195 - accuracy: 0.8594 - val_loss: 0.3487 - val_accuracy: 0.8594\n",
      "Epoch 19/300\n",
      "967/967 [==============================] - 0s 14us/step - loss: 0.3189 - accuracy: 0.8604 - val_loss: 0.3483 - val_accuracy: 0.8594\n",
      "Epoch 20/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3183 - accuracy: 0.8604 - val_loss: 0.3480 - val_accuracy: 0.8594\n",
      "Epoch 21/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3176 - accuracy: 0.8604 - val_loss: 0.3477 - val_accuracy: 0.8625\n",
      "Epoch 22/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3172 - accuracy: 0.8604 - val_loss: 0.3474 - val_accuracy: 0.8594\n",
      "Epoch 23/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3166 - accuracy: 0.8604 - val_loss: 0.3471 - val_accuracy: 0.8594\n",
      "Epoch 24/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3162 - accuracy: 0.8594 - val_loss: 0.3469 - val_accuracy: 0.8594\n",
      "Epoch 25/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3157 - accuracy: 0.8594 - val_loss: 0.3466 - val_accuracy: 0.8604\n",
      "Epoch 26/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3151 - accuracy: 0.8594 - val_loss: 0.3465 - val_accuracy: 0.8583\n",
      "Epoch 27/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3147 - accuracy: 0.8594 - val_loss: 0.3464 - val_accuracy: 0.8573\n",
      "Epoch 28/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3145 - accuracy: 0.8614 - val_loss: 0.3464 - val_accuracy: 0.8573\n",
      "Epoch 29/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3141 - accuracy: 0.8594 - val_loss: 0.3462 - val_accuracy: 0.8583\n",
      "Epoch 30/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3137 - accuracy: 0.8594 - val_loss: 0.3460 - val_accuracy: 0.8573\n",
      "Epoch 31/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3135 - accuracy: 0.8594 - val_loss: 0.3458 - val_accuracy: 0.8552\n",
      "Epoch 32/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3132 - accuracy: 0.8625 - val_loss: 0.3458 - val_accuracy: 0.8563\n",
      "Epoch 33/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3128 - accuracy: 0.8625 - val_loss: 0.3457 - val_accuracy: 0.8573\n",
      "Epoch 34/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3125 - accuracy: 0.8614 - val_loss: 0.3456 - val_accuracy: 0.8563\n",
      "Epoch 35/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "967/967 [==============================] - 0s 15us/step - loss: 0.3122 - accuracy: 0.8625 - val_loss: 0.3455 - val_accuracy: 0.8583\n",
      "Epoch 36/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3121 - accuracy: 0.8625 - val_loss: 0.3454 - val_accuracy: 0.8583\n",
      "Epoch 37/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3118 - accuracy: 0.8625 - val_loss: 0.3453 - val_accuracy: 0.8583\n",
      "Epoch 38/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3116 - accuracy: 0.8614 - val_loss: 0.3453 - val_accuracy: 0.8594\n",
      "Epoch 39/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3114 - accuracy: 0.8625 - val_loss: 0.3453 - val_accuracy: 0.8594\n",
      "Epoch 40/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3112 - accuracy: 0.8635 - val_loss: 0.3452 - val_accuracy: 0.8594\n",
      "Epoch 41/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3109 - accuracy: 0.8614 - val_loss: 0.3451 - val_accuracy: 0.8594\n",
      "Epoch 42/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3108 - accuracy: 0.8625 - val_loss: 0.3450 - val_accuracy: 0.8604\n",
      "Epoch 43/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3106 - accuracy: 0.8614 - val_loss: 0.3449 - val_accuracy: 0.8604\n",
      "Epoch 44/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3104 - accuracy: 0.8635 - val_loss: 0.3449 - val_accuracy: 0.8614\n",
      "Epoch 45/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3103 - accuracy: 0.8625 - val_loss: 0.3449 - val_accuracy: 0.8614\n",
      "Epoch 46/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3100 - accuracy: 0.8614 - val_loss: 0.3449 - val_accuracy: 0.8625\n",
      "Epoch 47/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3100 - accuracy: 0.8614 - val_loss: 0.3448 - val_accuracy: 0.8625\n",
      "Epoch 48/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3098 - accuracy: 0.8625 - val_loss: 0.3447 - val_accuracy: 0.8625\n",
      "Epoch 49/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3096 - accuracy: 0.8625 - val_loss: 0.3447 - val_accuracy: 0.8635\n",
      "Epoch 50/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3094 - accuracy: 0.8625 - val_loss: 0.3447 - val_accuracy: 0.8635\n",
      "Epoch 51/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3093 - accuracy: 0.8625 - val_loss: 0.3447 - val_accuracy: 0.8635\n",
      "Epoch 52/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3092 - accuracy: 0.8625 - val_loss: 0.3447 - val_accuracy: 0.8645\n",
      "Epoch 53/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3091 - accuracy: 0.8635 - val_loss: 0.3447 - val_accuracy: 0.8645\n",
      "Epoch 54/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3091 - accuracy: 0.8635 - val_loss: 0.3447 - val_accuracy: 0.8635\n",
      "Epoch 55/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3089 - accuracy: 0.8635 - val_loss: 0.3446 - val_accuracy: 0.8635\n",
      "Epoch 56/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3087 - accuracy: 0.8635 - val_loss: 0.3446 - val_accuracy: 0.8635\n",
      "Epoch 57/300\n",
      "967/967 [==============================] - 0s 14us/step - loss: 0.3086 - accuracy: 0.8635 - val_loss: 0.3445 - val_accuracy: 0.8635\n",
      "Epoch 58/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3085 - accuracy: 0.8645 - val_loss: 0.3445 - val_accuracy: 0.8635\n",
      "Epoch 59/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3085 - accuracy: 0.8666 - val_loss: 0.3445 - val_accuracy: 0.8635\n",
      "Epoch 60/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3084 - accuracy: 0.8687 - val_loss: 0.3445 - val_accuracy: 0.8635\n",
      "Epoch 61/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3082 - accuracy: 0.8687 - val_loss: 0.3446 - val_accuracy: 0.8635\n",
      "Epoch 62/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3081 - accuracy: 0.8676 - val_loss: 0.3446 - val_accuracy: 0.8635\n",
      "Epoch 63/300\n",
      "967/967 [==============================] - 0s 14us/step - loss: 0.3080 - accuracy: 0.8687 - val_loss: 0.3446 - val_accuracy: 0.8635\n",
      "Epoch 64/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3077 - accuracy: 0.8687 - val_loss: 0.3446 - val_accuracy: 0.8635\n",
      "Epoch 65/300\n",
      "967/967 [==============================] - ETA: 0s - loss: 0.3012 - accuracy: 0.88 - 0s 15us/step - loss: 0.3078 - accuracy: 0.8697 - val_loss: 0.3445 - val_accuracy: 0.8635\n",
      "Epoch 66/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3077 - accuracy: 0.8707 - val_loss: 0.3446 - val_accuracy: 0.8635\n",
      "Epoch 67/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3076 - accuracy: 0.8697 - val_loss: 0.3446 - val_accuracy: 0.8645\n",
      "Epoch 68/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3075 - accuracy: 0.8697 - val_loss: 0.3446 - val_accuracy: 0.8645\n",
      "Epoch 69/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3075 - accuracy: 0.8666 - val_loss: 0.3446 - val_accuracy: 0.8645\n",
      "Epoch 70/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3073 - accuracy: 0.8697 - val_loss: 0.3446 - val_accuracy: 0.8645\n",
      "Epoch 71/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3074 - accuracy: 0.8676 - val_loss: 0.3446 - val_accuracy: 0.8635\n",
      "Epoch 72/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3072 - accuracy: 0.8676 - val_loss: 0.3446 - val_accuracy: 0.8635\n",
      "Epoch 73/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3071 - accuracy: 0.8687 - val_loss: 0.3447 - val_accuracy: 0.8635\n",
      "Epoch 74/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3070 - accuracy: 0.8687 - val_loss: 0.3447 - val_accuracy: 0.8645\n",
      "Epoch 75/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3069 - accuracy: 0.8697 - val_loss: 0.3447 - val_accuracy: 0.8656\n",
      "Epoch 76/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3068 - accuracy: 0.8687 - val_loss: 0.3447 - val_accuracy: 0.8656\n",
      "Epoch 77/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3068 - accuracy: 0.8697 - val_loss: 0.3447 - val_accuracy: 0.8645\n",
      "Epoch 78/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3068 - accuracy: 0.8687 - val_loss: 0.3446 - val_accuracy: 0.8645\n",
      "Epoch 79/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3066 - accuracy: 0.8687 - val_loss: 0.3446 - val_accuracy: 0.8645\n",
      "Epoch 80/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3066 - accuracy: 0.8687 - val_loss: 0.3446 - val_accuracy: 0.8645\n",
      "Epoch 81/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3066 - accuracy: 0.8687 - val_loss: 0.3446 - val_accuracy: 0.8645\n",
      "Epoch 82/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3064 - accuracy: 0.8697 - val_loss: 0.3446 - val_accuracy: 0.8645\n",
      "Epoch 83/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3064 - accuracy: 0.8676 - val_loss: 0.3446 - val_accuracy: 0.8635\n",
      "Epoch 84/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3063 - accuracy: 0.8687 - val_loss: 0.3446 - val_accuracy: 0.8635\n",
      "Epoch 85/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3063 - accuracy: 0.8687 - val_loss: 0.3447 - val_accuracy: 0.8635\n",
      "Epoch 86/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3063 - accuracy: 0.8687 - val_loss: 0.3447 - val_accuracy: 0.8635\n",
      "Epoch 87/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3061 - accuracy: 0.8697 - val_loss: 0.3447 - val_accuracy: 0.8635\n",
      "Epoch 88/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3062 - accuracy: 0.8676 - val_loss: 0.3447 - val_accuracy: 0.8635\n",
      "Epoch 89/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3060 - accuracy: 0.8697 - val_loss: 0.3447 - val_accuracy: 0.8635\n",
      "Epoch 90/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3060 - accuracy: 0.8687 - val_loss: 0.3448 - val_accuracy: 0.8635\n",
      "Epoch 91/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "967/967 [==============================] - 0s 17us/step - loss: 0.3059 - accuracy: 0.8676 - val_loss: 0.3447 - val_accuracy: 0.8635\n",
      "Epoch 92/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3059 - accuracy: 0.8687 - val_loss: 0.3446 - val_accuracy: 0.8635\n",
      "Epoch 93/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3058 - accuracy: 0.8697 - val_loss: 0.3446 - val_accuracy: 0.8635\n",
      "Epoch 94/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3057 - accuracy: 0.8687 - val_loss: 0.3447 - val_accuracy: 0.8635\n",
      "Epoch 95/300\n",
      "967/967 [==============================] - 0s 14us/step - loss: 0.3058 - accuracy: 0.8697 - val_loss: 0.3447 - val_accuracy: 0.8645\n",
      "Epoch 96/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3057 - accuracy: 0.8697 - val_loss: 0.3448 - val_accuracy: 0.8645\n",
      "Epoch 97/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3057 - accuracy: 0.8697 - val_loss: 0.3448 - val_accuracy: 0.8645\n",
      "Epoch 98/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3056 - accuracy: 0.8687 - val_loss: 0.3448 - val_accuracy: 0.8645\n",
      "Epoch 99/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3055 - accuracy: 0.8707 - val_loss: 0.3448 - val_accuracy: 0.8645\n",
      "Epoch 100/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3055 - accuracy: 0.8707 - val_loss: 0.3448 - val_accuracy: 0.8645\n",
      "Epoch 101/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3054 - accuracy: 0.8707 - val_loss: 0.3448 - val_accuracy: 0.8645\n",
      "Epoch 102/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3054 - accuracy: 0.8697 - val_loss: 0.3448 - val_accuracy: 0.8645\n",
      "Epoch 103/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3054 - accuracy: 0.8707 - val_loss: 0.3447 - val_accuracy: 0.8645\n",
      "Epoch 104/300\n",
      "967/967 [==============================] - 0s 18us/step - loss: 0.3053 - accuracy: 0.8707 - val_loss: 0.3448 - val_accuracy: 0.8645\n",
      "Epoch 105/300\n",
      "967/967 [==============================] - 0s 18us/step - loss: 0.3052 - accuracy: 0.8718 - val_loss: 0.3448 - val_accuracy: 0.8645\n",
      "Epoch 106/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3052 - accuracy: 0.8707 - val_loss: 0.3448 - val_accuracy: 0.8645\n",
      "Epoch 107/300\n",
      "967/967 [==============================] - 0s 18us/step - loss: 0.3053 - accuracy: 0.8718 - val_loss: 0.3448 - val_accuracy: 0.8645\n",
      "Epoch 108/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3051 - accuracy: 0.8728 - val_loss: 0.3448 - val_accuracy: 0.8645\n",
      "Epoch 109/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3051 - accuracy: 0.8728 - val_loss: 0.3448 - val_accuracy: 0.8645\n",
      "Epoch 110/300\n",
      "967/967 [==============================] - 0s 18us/step - loss: 0.3050 - accuracy: 0.8728 - val_loss: 0.3448 - val_accuracy: 0.8656\n",
      "Epoch 111/300\n",
      "967/967 [==============================] - 0s 18us/step - loss: 0.3050 - accuracy: 0.8728 - val_loss: 0.3448 - val_accuracy: 0.8645\n",
      "Epoch 112/300\n",
      "967/967 [==============================] - 0s 18us/step - loss: 0.3050 - accuracy: 0.8728 - val_loss: 0.3448 - val_accuracy: 0.8635\n",
      "Epoch 113/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3050 - accuracy: 0.8718 - val_loss: 0.3447 - val_accuracy: 0.8635\n",
      "Epoch 114/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3050 - accuracy: 0.8718 - val_loss: 0.3448 - val_accuracy: 0.8656\n",
      "Epoch 115/300\n",
      "967/967 [==============================] - 0s 19us/step - loss: 0.3048 - accuracy: 0.8728 - val_loss: 0.3448 - val_accuracy: 0.8666\n",
      "Epoch 116/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3049 - accuracy: 0.8738 - val_loss: 0.3448 - val_accuracy: 0.8645\n",
      "Epoch 117/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3048 - accuracy: 0.8718 - val_loss: 0.3449 - val_accuracy: 0.8645\n",
      "Epoch 118/300\n",
      "967/967 [==============================] - 0s 18us/step - loss: 0.3048 - accuracy: 0.8728 - val_loss: 0.3449 - val_accuracy: 0.8645\n",
      "Epoch 119/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3048 - accuracy: 0.8728 - val_loss: 0.3449 - val_accuracy: 0.8645\n",
      "Epoch 120/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3047 - accuracy: 0.8728 - val_loss: 0.3449 - val_accuracy: 0.8656\n",
      "Epoch 121/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3047 - accuracy: 0.8718 - val_loss: 0.3450 - val_accuracy: 0.8645\n",
      "Epoch 122/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3046 - accuracy: 0.8728 - val_loss: 0.3450 - val_accuracy: 0.8645\n",
      "Epoch 123/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3047 - accuracy: 0.8718 - val_loss: 0.3450 - val_accuracy: 0.8645\n",
      "Epoch 124/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3045 - accuracy: 0.8728 - val_loss: 0.3451 - val_accuracy: 0.8645\n",
      "Epoch 125/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3045 - accuracy: 0.8718 - val_loss: 0.3451 - val_accuracy: 0.8656\n",
      "Epoch 126/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3044 - accuracy: 0.8707 - val_loss: 0.3451 - val_accuracy: 0.8645\n",
      "Epoch 127/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3045 - accuracy: 0.8718 - val_loss: 0.3451 - val_accuracy: 0.8645\n",
      "Epoch 128/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3044 - accuracy: 0.8718 - val_loss: 0.3451 - val_accuracy: 0.8656\n",
      "Epoch 129/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3044 - accuracy: 0.8718 - val_loss: 0.3451 - val_accuracy: 0.8645\n",
      "Epoch 130/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3043 - accuracy: 0.8707 - val_loss: 0.3451 - val_accuracy: 0.8645\n",
      "Epoch 131/300\n",
      "967/967 [==============================] - 0s 18us/step - loss: 0.3044 - accuracy: 0.8718 - val_loss: 0.3451 - val_accuracy: 0.8645\n",
      "Epoch 132/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3044 - accuracy: 0.8697 - val_loss: 0.3451 - val_accuracy: 0.8645\n",
      "Epoch 133/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3043 - accuracy: 0.8718 - val_loss: 0.3450 - val_accuracy: 0.8635\n",
      "Epoch 134/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3042 - accuracy: 0.8707 - val_loss: 0.3451 - val_accuracy: 0.8645\n",
      "Epoch 135/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3041 - accuracy: 0.8718 - val_loss: 0.3451 - val_accuracy: 0.8635\n",
      "Epoch 136/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3044 - accuracy: 0.8707 - val_loss: 0.3451 - val_accuracy: 0.8635\n",
      "Epoch 137/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3042 - accuracy: 0.8707 - val_loss: 0.3451 - val_accuracy: 0.8625\n",
      "Epoch 138/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3041 - accuracy: 0.8687 - val_loss: 0.3451 - val_accuracy: 0.8635\n",
      "Epoch 139/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3042 - accuracy: 0.8707 - val_loss: 0.3452 - val_accuracy: 0.8635\n",
      "Epoch 140/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3041 - accuracy: 0.8707 - val_loss: 0.3453 - val_accuracy: 0.8635\n",
      "Epoch 141/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3040 - accuracy: 0.8697 - val_loss: 0.3453 - val_accuracy: 0.8635\n",
      "Epoch 142/300\n",
      "967/967 [==============================] - 0s 18us/step - loss: 0.3040 - accuracy: 0.8707 - val_loss: 0.3453 - val_accuracy: 0.8645\n",
      "Epoch 143/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3040 - accuracy: 0.8697 - val_loss: 0.3453 - val_accuracy: 0.8645\n",
      "Epoch 144/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3041 - accuracy: 0.8707 - val_loss: 0.3453 - val_accuracy: 0.8635\n",
      "Epoch 145/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3039 - accuracy: 0.8718 - val_loss: 0.3454 - val_accuracy: 0.8645\n",
      "Epoch 146/300\n",
      "967/967 [==============================] - 0s 18us/step - loss: 0.3040 - accuracy: 0.8707 - val_loss: 0.3454 - val_accuracy: 0.8645\n",
      "Epoch 147/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "967/967 [==============================] - 0s 16us/step - loss: 0.3040 - accuracy: 0.8707 - val_loss: 0.3454 - val_accuracy: 0.8635\n",
      "Epoch 148/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3040 - accuracy: 0.8707 - val_loss: 0.3454 - val_accuracy: 0.8625\n",
      "Epoch 149/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3038 - accuracy: 0.8718 - val_loss: 0.3454 - val_accuracy: 0.8635\n",
      "Epoch 150/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3038 - accuracy: 0.8718 - val_loss: 0.3454 - val_accuracy: 0.8635\n",
      "Epoch 151/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3038 - accuracy: 0.8728 - val_loss: 0.3454 - val_accuracy: 0.8635\n",
      "Epoch 152/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3037 - accuracy: 0.8718 - val_loss: 0.3454 - val_accuracy: 0.8635\n",
      "Epoch 153/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3038 - accuracy: 0.8718 - val_loss: 0.3454 - val_accuracy: 0.8614\n",
      "Epoch 154/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3037 - accuracy: 0.8707 - val_loss: 0.3454 - val_accuracy: 0.8604\n",
      "Epoch 155/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3037 - accuracy: 0.8697 - val_loss: 0.3455 - val_accuracy: 0.8614\n",
      "Epoch 156/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3037 - accuracy: 0.8697 - val_loss: 0.3455 - val_accuracy: 0.8614\n",
      "Epoch 157/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3036 - accuracy: 0.8728 - val_loss: 0.3456 - val_accuracy: 0.8614\n",
      "Epoch 158/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3036 - accuracy: 0.8697 - val_loss: 0.3456 - val_accuracy: 0.8614\n",
      "Epoch 159/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3038 - accuracy: 0.8697 - val_loss: 0.3456 - val_accuracy: 0.8604\n",
      "Epoch 160/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3035 - accuracy: 0.8728 - val_loss: 0.3456 - val_accuracy: 0.8614\n",
      "Epoch 161/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3035 - accuracy: 0.8697 - val_loss: 0.3456 - val_accuracy: 0.8614\n",
      "Epoch 162/300\n",
      "967/967 [==============================] - 0s 18us/step - loss: 0.3036 - accuracy: 0.8718 - val_loss: 0.3456 - val_accuracy: 0.8614\n",
      "Epoch 163/300\n",
      "967/967 [==============================] - ETA: 0s - loss: 0.4071 - accuracy: 0.83 - 0s 16us/step - loss: 0.3035 - accuracy: 0.8707 - val_loss: 0.3456 - val_accuracy: 0.8614\n",
      "Epoch 164/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3035 - accuracy: 0.8707 - val_loss: 0.3456 - val_accuracy: 0.8614\n",
      "Epoch 165/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3035 - accuracy: 0.8728 - val_loss: 0.3456 - val_accuracy: 0.8614\n",
      "Epoch 166/300\n",
      "967/967 [==============================] - 0s 18us/step - loss: 0.3034 - accuracy: 0.8718 - val_loss: 0.3457 - val_accuracy: 0.8614\n",
      "Epoch 167/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3034 - accuracy: 0.8718 - val_loss: 0.3457 - val_accuracy: 0.8614\n",
      "Epoch 168/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3034 - accuracy: 0.8718 - val_loss: 0.3457 - val_accuracy: 0.8614\n",
      "Epoch 169/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3033 - accuracy: 0.8718 - val_loss: 0.3458 - val_accuracy: 0.8614\n",
      "Epoch 170/300\n",
      "967/967 [==============================] - 0s 14us/step - loss: 0.3034 - accuracy: 0.8707 - val_loss: 0.3458 - val_accuracy: 0.8614\n",
      "Epoch 171/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3033 - accuracy: 0.8707 - val_loss: 0.3458 - val_accuracy: 0.8614\n",
      "Epoch 172/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3033 - accuracy: 0.8718 - val_loss: 0.3458 - val_accuracy: 0.8614\n",
      "Epoch 173/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3035 - accuracy: 0.8718 - val_loss: 0.3458 - val_accuracy: 0.8604\n",
      "Epoch 174/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3034 - accuracy: 0.8697 - val_loss: 0.3458 - val_accuracy: 0.8604\n",
      "Epoch 175/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3032 - accuracy: 0.8718 - val_loss: 0.3459 - val_accuracy: 0.8604\n",
      "Epoch 176/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3033 - accuracy: 0.8718 - val_loss: 0.3459 - val_accuracy: 0.8614\n",
      "Epoch 177/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3033 - accuracy: 0.8707 - val_loss: 0.3460 - val_accuracy: 0.8614\n",
      "Epoch 178/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3032 - accuracy: 0.8707 - val_loss: 0.3460 - val_accuracy: 0.8614\n",
      "Epoch 179/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3032 - accuracy: 0.8697 - val_loss: 0.3460 - val_accuracy: 0.8604\n",
      "Epoch 180/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3031 - accuracy: 0.8697 - val_loss: 0.3459 - val_accuracy: 0.8614\n",
      "Epoch 181/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3032 - accuracy: 0.8718 - val_loss: 0.3458 - val_accuracy: 0.8594\n",
      "Epoch 182/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3032 - accuracy: 0.8718 - val_loss: 0.3459 - val_accuracy: 0.8594\n",
      "Epoch 183/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3031 - accuracy: 0.8718 - val_loss: 0.3458 - val_accuracy: 0.8583\n",
      "Epoch 184/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3031 - accuracy: 0.8718 - val_loss: 0.3458 - val_accuracy: 0.8583\n",
      "Epoch 185/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3031 - accuracy: 0.8718 - val_loss: 0.3459 - val_accuracy: 0.8583\n",
      "Epoch 186/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3030 - accuracy: 0.8707 - val_loss: 0.3459 - val_accuracy: 0.8583\n",
      "Epoch 187/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3031 - accuracy: 0.8718 - val_loss: 0.3459 - val_accuracy: 0.8583\n",
      "Epoch 188/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3031 - accuracy: 0.8718 - val_loss: 0.3459 - val_accuracy: 0.8583\n",
      "Epoch 189/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3030 - accuracy: 0.8718 - val_loss: 0.3460 - val_accuracy: 0.8594\n",
      "Epoch 190/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3030 - accuracy: 0.8718 - val_loss: 0.3460 - val_accuracy: 0.8594\n",
      "Epoch 191/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3030 - accuracy: 0.8728 - val_loss: 0.3460 - val_accuracy: 0.8594\n",
      "Epoch 192/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3030 - accuracy: 0.8697 - val_loss: 0.3460 - val_accuracy: 0.8594\n",
      "Epoch 193/300\n",
      "967/967 [==============================] - ETA: 0s - loss: 0.3148 - accuracy: 0.82 - 0s 18us/step - loss: 0.3030 - accuracy: 0.8707 - val_loss: 0.3460 - val_accuracy: 0.8583\n",
      "Epoch 194/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3029 - accuracy: 0.8707 - val_loss: 0.3460 - val_accuracy: 0.8583\n",
      "Epoch 195/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3028 - accuracy: 0.8718 - val_loss: 0.3460 - val_accuracy: 0.8573\n",
      "Epoch 196/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3029 - accuracy: 0.8707 - val_loss: 0.3461 - val_accuracy: 0.8583\n",
      "Epoch 197/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3029 - accuracy: 0.8707 - val_loss: 0.3460 - val_accuracy: 0.8573\n",
      "Epoch 198/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3030 - accuracy: 0.8738 - val_loss: 0.3461 - val_accuracy: 0.8583\n",
      "Epoch 199/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3028 - accuracy: 0.8718 - val_loss: 0.3461 - val_accuracy: 0.8583\n",
      "Epoch 200/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3029 - accuracy: 0.8707 - val_loss: 0.3461 - val_accuracy: 0.8583\n",
      "Epoch 201/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3028 - accuracy: 0.8718 - val_loss: 0.3461 - val_accuracy: 0.8583\n",
      "Epoch 202/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "967/967 [==============================] - 0s 15us/step - loss: 0.3029 - accuracy: 0.8718 - val_loss: 0.3461 - val_accuracy: 0.8583\n",
      "Epoch 203/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3029 - accuracy: 0.8707 - val_loss: 0.3461 - val_accuracy: 0.8583\n",
      "Epoch 204/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3029 - accuracy: 0.8718 - val_loss: 0.3461 - val_accuracy: 0.8583\n",
      "Epoch 205/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3028 - accuracy: 0.8707 - val_loss: 0.3461 - val_accuracy: 0.8583\n",
      "Epoch 206/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3028 - accuracy: 0.8728 - val_loss: 0.3462 - val_accuracy: 0.8583\n",
      "Epoch 207/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3027 - accuracy: 0.8718 - val_loss: 0.3462 - val_accuracy: 0.8573\n",
      "Epoch 208/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3027 - accuracy: 0.8718 - val_loss: 0.3462 - val_accuracy: 0.8583\n",
      "Epoch 209/300\n",
      "967/967 [==============================] - 0s 14us/step - loss: 0.3028 - accuracy: 0.8718 - val_loss: 0.3462 - val_accuracy: 0.8583\n",
      "Epoch 210/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3027 - accuracy: 0.8738 - val_loss: 0.3462 - val_accuracy: 0.8583\n",
      "Epoch 211/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3028 - accuracy: 0.8718 - val_loss: 0.3462 - val_accuracy: 0.8594\n",
      "Epoch 212/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3028 - accuracy: 0.8718 - val_loss: 0.3462 - val_accuracy: 0.8583\n",
      "Epoch 213/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3027 - accuracy: 0.8728 - val_loss: 0.3462 - val_accuracy: 0.8583\n",
      "Epoch 214/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3027 - accuracy: 0.8728 - val_loss: 0.3462 - val_accuracy: 0.8583\n",
      "Epoch 215/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3027 - accuracy: 0.8738 - val_loss: 0.3463 - val_accuracy: 0.8573\n",
      "Epoch 216/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3026 - accuracy: 0.8738 - val_loss: 0.3463 - val_accuracy: 0.8583\n",
      "Epoch 217/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3027 - accuracy: 0.8707 - val_loss: 0.3463 - val_accuracy: 0.8573\n",
      "Epoch 218/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3027 - accuracy: 0.8728 - val_loss: 0.3463 - val_accuracy: 0.8573\n",
      "Epoch 219/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3027 - accuracy: 0.8728 - val_loss: 0.3463 - val_accuracy: 0.8573\n",
      "Epoch 220/300\n",
      "967/967 [==============================] - 0s 14us/step - loss: 0.3027 - accuracy: 0.8728 - val_loss: 0.3463 - val_accuracy: 0.8573\n",
      "Epoch 221/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3026 - accuracy: 0.8728 - val_loss: 0.3464 - val_accuracy: 0.8583\n",
      "Epoch 222/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3025 - accuracy: 0.8718 - val_loss: 0.3464 - val_accuracy: 0.8583\n",
      "Epoch 223/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3026 - accuracy: 0.8728 - val_loss: 0.3464 - val_accuracy: 0.8583\n",
      "Epoch 224/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3027 - accuracy: 0.8728 - val_loss: 0.3464 - val_accuracy: 0.8594\n",
      "Epoch 225/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3026 - accuracy: 0.8728 - val_loss: 0.3463 - val_accuracy: 0.8594\n",
      "Epoch 226/300\n",
      "967/967 [==============================] - 0s 14us/step - loss: 0.3026 - accuracy: 0.8718 - val_loss: 0.3463 - val_accuracy: 0.8604\n",
      "Epoch 227/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3025 - accuracy: 0.8738 - val_loss: 0.3463 - val_accuracy: 0.8604\n",
      "Epoch 228/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3025 - accuracy: 0.8718 - val_loss: 0.3464 - val_accuracy: 0.8594\n",
      "Epoch 229/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3025 - accuracy: 0.8728 - val_loss: 0.3464 - val_accuracy: 0.8594\n",
      "Epoch 230/300\n",
      "967/967 [==============================] - 0s 14us/step - loss: 0.3026 - accuracy: 0.8728 - val_loss: 0.3464 - val_accuracy: 0.8583\n",
      "Epoch 231/300\n",
      "967/967 [==============================] - 0s 18us/step - loss: 0.3025 - accuracy: 0.8728 - val_loss: 0.3464 - val_accuracy: 0.8583\n",
      "Epoch 232/300\n",
      "967/967 [==============================] - 0s 14us/step - loss: 0.3024 - accuracy: 0.8728 - val_loss: 0.3464 - val_accuracy: 0.8583\n",
      "Epoch 233/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3025 - accuracy: 0.8728 - val_loss: 0.3464 - val_accuracy: 0.8594\n",
      "Epoch 234/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3024 - accuracy: 0.8728 - val_loss: 0.3464 - val_accuracy: 0.8614\n",
      "Epoch 235/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3025 - accuracy: 0.8728 - val_loss: 0.3464 - val_accuracy: 0.8614\n",
      "Epoch 236/300\n",
      "967/967 [==============================] - 0s 14us/step - loss: 0.3025 - accuracy: 0.8728 - val_loss: 0.3465 - val_accuracy: 0.8594\n",
      "Epoch 237/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3024 - accuracy: 0.8728 - val_loss: 0.3465 - val_accuracy: 0.8604\n",
      "Epoch 238/300\n",
      "967/967 [==============================] - 0s 14us/step - loss: 0.3023 - accuracy: 0.8728 - val_loss: 0.3465 - val_accuracy: 0.8604\n",
      "Epoch 239/300\n",
      "967/967 [==============================] - 0s 14us/step - loss: 0.3023 - accuracy: 0.8728 - val_loss: 0.3465 - val_accuracy: 0.8594\n",
      "Epoch 240/300\n",
      "967/967 [==============================] - 0s 14us/step - loss: 0.3024 - accuracy: 0.8728 - val_loss: 0.3466 - val_accuracy: 0.8594\n",
      "Epoch 241/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3023 - accuracy: 0.8728 - val_loss: 0.3465 - val_accuracy: 0.8594\n",
      "Epoch 242/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3024 - accuracy: 0.8728 - val_loss: 0.3465 - val_accuracy: 0.8604\n",
      "Epoch 243/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3023 - accuracy: 0.8728 - val_loss: 0.3465 - val_accuracy: 0.8604\n",
      "Epoch 244/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3024 - accuracy: 0.8718 - val_loss: 0.3466 - val_accuracy: 0.8604\n",
      "Epoch 245/300\n",
      "967/967 [==============================] - 0s 14us/step - loss: 0.3023 - accuracy: 0.8728 - val_loss: 0.3465 - val_accuracy: 0.8604\n",
      "Epoch 246/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3024 - accuracy: 0.8728 - val_loss: 0.3466 - val_accuracy: 0.8614\n",
      "Epoch 247/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3022 - accuracy: 0.8728 - val_loss: 0.3466 - val_accuracy: 0.8604\n",
      "Epoch 248/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3024 - accuracy: 0.8728 - val_loss: 0.3467 - val_accuracy: 0.8594\n",
      "Epoch 249/300\n",
      "967/967 [==============================] - 0s 17us/step - loss: 0.3023 - accuracy: 0.8728 - val_loss: 0.3467 - val_accuracy: 0.8594\n",
      "Epoch 250/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3023 - accuracy: 0.8718 - val_loss: 0.3468 - val_accuracy: 0.8594\n",
      "Epoch 251/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3023 - accuracy: 0.8728 - val_loss: 0.3468 - val_accuracy: 0.8594\n",
      "Epoch 252/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3023 - accuracy: 0.8728 - val_loss: 0.3468 - val_accuracy: 0.8594\n",
      "Epoch 253/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3023 - accuracy: 0.8718 - val_loss: 0.3467 - val_accuracy: 0.8604\n",
      "Epoch 254/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3022 - accuracy: 0.8728 - val_loss: 0.3468 - val_accuracy: 0.8604\n",
      "Epoch 255/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3021 - accuracy: 0.8728 - val_loss: 0.3468 - val_accuracy: 0.8604\n",
      "Epoch 256/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3023 - accuracy: 0.8728 - val_loss: 0.3468 - val_accuracy: 0.8604\n",
      "Epoch 257/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3022 - accuracy: 0.8728 - val_loss: 0.3468 - val_accuracy: 0.8614\n",
      "Epoch 258/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "967/967 [==============================] - 0s 15us/step - loss: 0.3022 - accuracy: 0.8718 - val_loss: 0.3468 - val_accuracy: 0.8614\n",
      "Epoch 259/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3023 - accuracy: 0.8728 - val_loss: 0.3468 - val_accuracy: 0.8604\n",
      "Epoch 260/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3023 - accuracy: 0.8718 - val_loss: 0.3468 - val_accuracy: 0.8604\n",
      "Epoch 261/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3022 - accuracy: 0.8718 - val_loss: 0.3468 - val_accuracy: 0.8604\n",
      "Epoch 262/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3022 - accuracy: 0.8718 - val_loss: 0.3468 - val_accuracy: 0.8604\n",
      "Epoch 263/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3021 - accuracy: 0.8728 - val_loss: 0.3468 - val_accuracy: 0.8614\n",
      "Epoch 264/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3021 - accuracy: 0.8728 - val_loss: 0.3469 - val_accuracy: 0.8604\n",
      "Epoch 265/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3021 - accuracy: 0.8728 - val_loss: 0.3469 - val_accuracy: 0.8604\n",
      "Epoch 266/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3021 - accuracy: 0.8728 - val_loss: 0.3469 - val_accuracy: 0.8604\n",
      "Epoch 267/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3023 - accuracy: 0.8718 - val_loss: 0.3468 - val_accuracy: 0.8614\n",
      "Epoch 268/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3021 - accuracy: 0.8728 - val_loss: 0.3468 - val_accuracy: 0.8614\n",
      "Epoch 269/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3021 - accuracy: 0.8728 - val_loss: 0.3468 - val_accuracy: 0.8625\n",
      "Epoch 270/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3022 - accuracy: 0.8718 - val_loss: 0.3468 - val_accuracy: 0.8625\n",
      "Epoch 271/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3021 - accuracy: 0.8718 - val_loss: 0.3469 - val_accuracy: 0.8625\n",
      "Epoch 272/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3020 - accuracy: 0.8718 - val_loss: 0.3470 - val_accuracy: 0.8614\n",
      "Epoch 273/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3021 - accuracy: 0.8718 - val_loss: 0.3470 - val_accuracy: 0.8614\n",
      "Epoch 274/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3021 - accuracy: 0.8718 - val_loss: 0.3471 - val_accuracy: 0.8614\n",
      "Epoch 275/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3021 - accuracy: 0.8718 - val_loss: 0.3471 - val_accuracy: 0.8604\n",
      "Epoch 276/300\n",
      "967/967 [==============================] - 0s 14us/step - loss: 0.3020 - accuracy: 0.8728 - val_loss: 0.3471 - val_accuracy: 0.8625\n",
      "Epoch 277/300\n",
      "967/967 [==============================] - 0s 14us/step - loss: 0.3020 - accuracy: 0.8728 - val_loss: 0.3471 - val_accuracy: 0.8614\n",
      "Epoch 278/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3020 - accuracy: 0.8718 - val_loss: 0.3471 - val_accuracy: 0.8614\n",
      "Epoch 279/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3020 - accuracy: 0.8718 - val_loss: 0.3471 - val_accuracy: 0.8614\n",
      "Epoch 280/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3020 - accuracy: 0.8728 - val_loss: 0.3470 - val_accuracy: 0.8614\n",
      "Epoch 281/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3021 - accuracy: 0.8718 - val_loss: 0.3470 - val_accuracy: 0.8625\n",
      "Epoch 282/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3019 - accuracy: 0.8718 - val_loss: 0.3470 - val_accuracy: 0.8625\n",
      "Epoch 283/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3020 - accuracy: 0.8718 - val_loss: 0.3471 - val_accuracy: 0.8625\n",
      "Epoch 284/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3020 - accuracy: 0.8728 - val_loss: 0.3471 - val_accuracy: 0.8614\n",
      "Epoch 285/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3019 - accuracy: 0.8718 - val_loss: 0.3471 - val_accuracy: 0.8614\n",
      "Epoch 286/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3020 - accuracy: 0.8718 - val_loss: 0.3471 - val_accuracy: 0.8625\n",
      "Epoch 287/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3019 - accuracy: 0.8728 - val_loss: 0.3471 - val_accuracy: 0.8614\n",
      "Epoch 288/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3019 - accuracy: 0.8718 - val_loss: 0.3471 - val_accuracy: 0.8625\n",
      "Epoch 289/300\n",
      "967/967 [==============================] - 0s 14us/step - loss: 0.3019 - accuracy: 0.8718 - val_loss: 0.3472 - val_accuracy: 0.8614\n",
      "Epoch 290/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3019 - accuracy: 0.8718 - val_loss: 0.3472 - val_accuracy: 0.8625\n",
      "Epoch 291/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3019 - accuracy: 0.8718 - val_loss: 0.3472 - val_accuracy: 0.8604\n",
      "Epoch 292/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3018 - accuracy: 0.8718 - val_loss: 0.3472 - val_accuracy: 0.8614\n",
      "Epoch 293/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3019 - accuracy: 0.8718 - val_loss: 0.3473 - val_accuracy: 0.8614\n",
      "Epoch 294/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3019 - accuracy: 0.8718 - val_loss: 0.3473 - val_accuracy: 0.8604\n",
      "Epoch 295/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3019 - accuracy: 0.8718 - val_loss: 0.3472 - val_accuracy: 0.8614\n",
      "Epoch 296/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3019 - accuracy: 0.8718 - val_loss: 0.3472 - val_accuracy: 0.8614\n",
      "Epoch 297/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3018 - accuracy: 0.8718 - val_loss: 0.3472 - val_accuracy: 0.8614\n",
      "Epoch 298/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3019 - accuracy: 0.8718 - val_loss: 0.3472 - val_accuracy: 0.8614\n",
      "Epoch 299/300\n",
      "967/967 [==============================] - 0s 16us/step - loss: 0.3018 - accuracy: 0.8718 - val_loss: 0.3473 - val_accuracy: 0.8604\n",
      "Epoch 300/300\n",
      "967/967 [==============================] - 0s 15us/step - loss: 0.3018 - accuracy: 0.8718 - val_loss: 0.3473 - val_accuracy: 0.8614\n",
      "Train on 27188 samples, validate on 27188 samples\n",
      "Epoch 1/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3558 - accuracy: 0.8505 - val_loss: 0.3411 - val_accuracy: 0.8592\n",
      "Epoch 2/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3407 - accuracy: 0.8577 - val_loss: 0.3346 - val_accuracy: 0.8621\n",
      "Epoch 3/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3369 - accuracy: 0.8580 - val_loss: 0.3320 - val_accuracy: 0.8638\n",
      "Epoch 4/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3346 - accuracy: 0.8598 - val_loss: 0.3296 - val_accuracy: 0.8653\n",
      "Epoch 5/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3329 - accuracy: 0.8613 - val_loss: 0.3281 - val_accuracy: 0.8656\n",
      "Epoch 6/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3315 - accuracy: 0.8612 - val_loss: 0.3270 - val_accuracy: 0.8660\n",
      "Epoch 7/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3304 - accuracy: 0.8612 - val_loss: 0.3256 - val_accuracy: 0.8667\n",
      "Epoch 8/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3294 - accuracy: 0.8621 - val_loss: 0.3246 - val_accuracy: 0.8673\n",
      "Epoch 9/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3286 - accuracy: 0.8627 - val_loss: 0.3239 - val_accuracy: 0.8671\n",
      "Epoch 10/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3277 - accuracy: 0.8625 - val_loss: 0.3229 - val_accuracy: 0.8672\n",
      "Epoch 11/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3270 - accuracy: 0.8630 - val_loss: 0.3221 - val_accuracy: 0.8679\n",
      "Epoch 12/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3264 - accuracy: 0.8640 - val_loss: 0.3218 - val_accuracy: 0.8683\n",
      "Epoch 13/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3258 - accuracy: 0.8633 - val_loss: 0.3210 - val_accuracy: 0.8684\n",
      "Epoch 14/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3253 - accuracy: 0.8636 - val_loss: 0.3206 - val_accuracy: 0.8686\n",
      "Epoch 15/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3249 - accuracy: 0.8642 - val_loss: 0.3202 - val_accuracy: 0.8687\n",
      "Epoch 16/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3245 - accuracy: 0.8643 - val_loss: 0.3197 - val_accuracy: 0.8690\n",
      "Epoch 17/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3241 - accuracy: 0.8642 - val_loss: 0.3193 - val_accuracy: 0.8690\n",
      "Epoch 18/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3238 - accuracy: 0.8645 - val_loss: 0.3191 - val_accuracy: 0.8685\n",
      "Epoch 19/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3235 - accuracy: 0.8649 - val_loss: 0.3192 - val_accuracy: 0.8683\n",
      "Epoch 20/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3233 - accuracy: 0.8654 - val_loss: 0.3184 - val_accuracy: 0.8696\n",
      "Epoch 21/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3230 - accuracy: 0.8649 - val_loss: 0.3182 - val_accuracy: 0.8696\n",
      "Epoch 22/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3228 - accuracy: 0.8651 - val_loss: 0.3180 - val_accuracy: 0.8692\n",
      "Epoch 23/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3225 - accuracy: 0.8655 - val_loss: 0.3181 - val_accuracy: 0.8691\n",
      "Epoch 24/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3224 - accuracy: 0.8657 - val_loss: 0.3176 - val_accuracy: 0.8699\n",
      "Epoch 25/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3223 - accuracy: 0.8653 - val_loss: 0.3178 - val_accuracy: 0.8697\n",
      "Epoch 26/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3220 - accuracy: 0.8650 - val_loss: 0.3173 - val_accuracy: 0.8695\n",
      "Epoch 27/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3219 - accuracy: 0.8652 - val_loss: 0.3171 - val_accuracy: 0.8698\n",
      "Epoch 28/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3217 - accuracy: 0.8655 - val_loss: 0.3169 - val_accuracy: 0.8699\n",
      "Epoch 29/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3217 - accuracy: 0.8652 - val_loss: 0.3170 - val_accuracy: 0.8694\n",
      "Epoch 30/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3215 - accuracy: 0.8655 - val_loss: 0.3167 - val_accuracy: 0.8698\n",
      "Epoch 31/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3214 - accuracy: 0.8653 - val_loss: 0.3169 - val_accuracy: 0.8701\n",
      "Epoch 32/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3213 - accuracy: 0.8658 - val_loss: 0.3165 - val_accuracy: 0.8699\n",
      "Epoch 33/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3212 - accuracy: 0.8655 - val_loss: 0.3164 - val_accuracy: 0.8698\n",
      "Epoch 34/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3211 - accuracy: 0.8656 - val_loss: 0.3165 - val_accuracy: 0.8697\n",
      "Epoch 35/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3210 - accuracy: 0.8665 - val_loss: 0.3162 - val_accuracy: 0.8696\n",
      "Epoch 36/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3210 - accuracy: 0.8656 - val_loss: 0.3161 - val_accuracy: 0.8698\n",
      "Epoch 37/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3209 - accuracy: 0.8660 - val_loss: 0.3161 - val_accuracy: 0.8695\n",
      "Epoch 38/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3208 - accuracy: 0.8666 - val_loss: 0.3166 - val_accuracy: 0.8696\n",
      "Epoch 39/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3208 - accuracy: 0.8653 - val_loss: 0.3161 - val_accuracy: 0.8696\n",
      "Epoch 40/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3207 - accuracy: 0.8657 - val_loss: 0.3160 - val_accuracy: 0.8694\n",
      "Epoch 41/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3207 - accuracy: 0.8655 - val_loss: 0.3158 - val_accuracy: 0.8702\n",
      "Epoch 42/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3207 - accuracy: 0.8657 - val_loss: 0.3161 - val_accuracy: 0.8696\n",
      "Epoch 43/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3206 - accuracy: 0.8655 - val_loss: 0.3157 - val_accuracy: 0.8698\n",
      "Epoch 44/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3205 - accuracy: 0.8656 - val_loss: 0.3156 - val_accuracy: 0.8699\n",
      "Epoch 45/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3205 - accuracy: 0.8663 - val_loss: 0.3159 - val_accuracy: 0.8699\n",
      "Epoch 46/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3205 - accuracy: 0.8661 - val_loss: 0.3157 - val_accuracy: 0.8698\n",
      "Epoch 47/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3204 - accuracy: 0.8659 - val_loss: 0.3157 - val_accuracy: 0.8700\n",
      "Epoch 48/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3204 - accuracy: 0.8657 - val_loss: 0.3155 - val_accuracy: 0.8702\n",
      "Epoch 49/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3204 - accuracy: 0.8662 - val_loss: 0.3154 - val_accuracy: 0.8701\n",
      "Epoch 50/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3204 - accuracy: 0.8655 - val_loss: 0.3154 - val_accuracy: 0.8701\n",
      "Epoch 51/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3203 - accuracy: 0.8662 - val_loss: 0.3154 - val_accuracy: 0.8702\n",
      "Epoch 52/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3203 - accuracy: 0.8655 - val_loss: 0.3153 - val_accuracy: 0.8703\n",
      "Epoch 53/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3203 - accuracy: 0.8661 - val_loss: 0.3154 - val_accuracy: 0.8705\n",
      "Epoch 54/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3202 - accuracy: 0.8659 - val_loss: 0.3153 - val_accuracy: 0.8700\n",
      "Epoch 55/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3203 - accuracy: 0.8659 - val_loss: 0.3152 - val_accuracy: 0.8703\n",
      "Epoch 56/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3202 - accuracy: 0.8660 - val_loss: 0.3154 - val_accuracy: 0.8701\n",
      "Epoch 57/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3202 - accuracy: 0.8654 - val_loss: 0.3155 - val_accuracy: 0.8701\n",
      "Epoch 58/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3202 - accuracy: 0.8660 - val_loss: 0.3155 - val_accuracy: 0.8703\n",
      "Epoch 59/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3202 - accuracy: 0.8659 - val_loss: 0.3153 - val_accuracy: 0.8703\n",
      "Epoch 60/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3201 - accuracy: 0.8663 - val_loss: 0.3151 - val_accuracy: 0.8700\n",
      "Epoch 61/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3202 - accuracy: 0.8659 - val_loss: 0.3152 - val_accuracy: 0.8702\n",
      "Epoch 62/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3201 - accuracy: 0.8660 - val_loss: 0.3154 - val_accuracy: 0.8699\n",
      "Epoch 63/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3201 - accuracy: 0.8658 - val_loss: 0.3152 - val_accuracy: 0.8702\n",
      "Epoch 64/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3201 - accuracy: 0.8659 - val_loss: 0.3154 - val_accuracy: 0.8703\n",
      "Epoch 65/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3201 - accuracy: 0.8662 - val_loss: 0.3151 - val_accuracy: 0.8700\n",
      "Epoch 66/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3202 - accuracy: 0.8661 - val_loss: 0.3151 - val_accuracy: 0.8701\n",
      "Epoch 67/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3201 - accuracy: 0.8661 - val_loss: 0.3151 - val_accuracy: 0.8701\n",
      "Epoch 68/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3201 - accuracy: 0.8659 - val_loss: 0.3154 - val_accuracy: 0.8703\n",
      "Epoch 69/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3201 - accuracy: 0.8657 - val_loss: 0.3153 - val_accuracy: 0.8701\n",
      "Epoch 70/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8664 - val_loss: 0.3150 - val_accuracy: 0.8704\n",
      "Epoch 71/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3201 - accuracy: 0.8663 - val_loss: 0.3151 - val_accuracy: 0.8700\n",
      "Epoch 72/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8660 - val_loss: 0.3153 - val_accuracy: 0.8699\n",
      "Epoch 73/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3201 - accuracy: 0.8662 - val_loss: 0.3153 - val_accuracy: 0.8701\n",
      "Epoch 74/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8663 - val_loss: 0.3155 - val_accuracy: 0.8696\n",
      "Epoch 75/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3201 - accuracy: 0.8656 - val_loss: 0.3151 - val_accuracy: 0.8702\n",
      "Epoch 76/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8660 - val_loss: 0.3149 - val_accuracy: 0.8703\n",
      "Epoch 77/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8654 - val_loss: 0.3150 - val_accuracy: 0.8700\n",
      "Epoch 78/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8657 - val_loss: 0.3152 - val_accuracy: 0.8696\n",
      "Epoch 79/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8670 - val_loss: 0.3150 - val_accuracy: 0.8699\n",
      "Epoch 80/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8661 - val_loss: 0.3152 - val_accuracy: 0.8700\n",
      "Epoch 81/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8656 - val_loss: 0.3150 - val_accuracy: 0.8696\n",
      "Epoch 82/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8661 - val_loss: 0.3154 - val_accuracy: 0.8698\n",
      "Epoch 83/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8660 - val_loss: 0.3154 - val_accuracy: 0.8697\n",
      "Epoch 84/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8663 - val_loss: 0.3149 - val_accuracy: 0.8699\n",
      "Epoch 85/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8659 - val_loss: 0.3152 - val_accuracy: 0.8699\n",
      "Epoch 86/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8664 - val_loss: 0.3150 - val_accuracy: 0.8703\n",
      "Epoch 87/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8663 - val_loss: 0.3150 - val_accuracy: 0.8701\n",
      "Epoch 88/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8659 - val_loss: 0.3150 - val_accuracy: 0.8703\n",
      "Epoch 89/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8658 - val_loss: 0.3152 - val_accuracy: 0.8703\n",
      "Epoch 90/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8661 - val_loss: 0.3150 - val_accuracy: 0.8702\n",
      "Epoch 91/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8661 - val_loss: 0.3151 - val_accuracy: 0.8701\n",
      "Epoch 92/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8658 - val_loss: 0.3149 - val_accuracy: 0.8701\n",
      "Epoch 93/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8663 - val_loss: 0.3149 - val_accuracy: 0.8702\n",
      "Epoch 94/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8659 - val_loss: 0.3150 - val_accuracy: 0.8704\n",
      "Epoch 95/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8658 - val_loss: 0.3151 - val_accuracy: 0.8703\n",
      "Epoch 96/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8659 - val_loss: 0.3154 - val_accuracy: 0.8696\n",
      "Epoch 97/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8663 - val_loss: 0.3153 - val_accuracy: 0.8699\n",
      "Epoch 98/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8658 - val_loss: 0.3153 - val_accuracy: 0.8698\n",
      "Epoch 99/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8657 - val_loss: 0.3149 - val_accuracy: 0.8700\n",
      "Epoch 100/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8659 - val_loss: 0.3149 - val_accuracy: 0.8704\n",
      "Epoch 101/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8662 - val_loss: 0.3149 - val_accuracy: 0.8701\n",
      "Epoch 102/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8659 - val_loss: 0.3151 - val_accuracy: 0.8695\n",
      "Epoch 103/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8660 - val_loss: 0.3152 - val_accuracy: 0.8701\n",
      "Epoch 104/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8660 - val_loss: 0.3150 - val_accuracy: 0.8709\n",
      "Epoch 105/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8661 - val_loss: 0.3148 - val_accuracy: 0.8705\n",
      "Epoch 106/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8660 - val_loss: 0.3149 - val_accuracy: 0.8704\n",
      "Epoch 107/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8662 - val_loss: 0.3150 - val_accuracy: 0.8705\n",
      "Epoch 108/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8656 - val_loss: 0.3153 - val_accuracy: 0.8702\n",
      "Epoch 109/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8659 - val_loss: 0.3149 - val_accuracy: 0.8703\n",
      "Epoch 110/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8661 - val_loss: 0.3150 - val_accuracy: 0.8703\n",
      "Epoch 111/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8655 - val_loss: 0.3149 - val_accuracy: 0.8702\n",
      "Epoch 112/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8665 - val_loss: 0.3148 - val_accuracy: 0.8701\n",
      "Epoch 113/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8663 - val_loss: 0.3151 - val_accuracy: 0.8701\n",
      "Epoch 114/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3198 - accuracy: 0.8661 - val_loss: 0.3149 - val_accuracy: 0.8704\n",
      "Epoch 115/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3198 - accuracy: 0.8666 - val_loss: 0.3160 - val_accuracy: 0.8692\n",
      "Epoch 116/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8664 - val_loss: 0.3150 - val_accuracy: 0.8699\n",
      "Epoch 117/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8657 - val_loss: 0.3148 - val_accuracy: 0.8699\n",
      "Epoch 118/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8659 - val_loss: 0.3149 - val_accuracy: 0.8705\n",
      "Epoch 119/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8661 - val_loss: 0.3154 - val_accuracy: 0.8695\n",
      "Epoch 120/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8659 - val_loss: 0.3148 - val_accuracy: 0.8705\n",
      "Epoch 121/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8659 - val_loss: 0.3153 - val_accuracy: 0.8697\n",
      "Epoch 122/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8665 - val_loss: 0.3152 - val_accuracy: 0.8696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8667 - val_loss: 0.3151 - val_accuracy: 0.8705\n",
      "Epoch 124/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8658 - val_loss: 0.3150 - val_accuracy: 0.8699\n",
      "Epoch 125/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8659 - val_loss: 0.3151 - val_accuracy: 0.8698\n",
      "Epoch 126/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8656 - val_loss: 0.3155 - val_accuracy: 0.8701\n",
      "Epoch 127/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8658 - val_loss: 0.3150 - val_accuracy: 0.8706\n",
      "Epoch 128/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8661 - val_loss: 0.3153 - val_accuracy: 0.8694\n",
      "Epoch 129/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8658 - val_loss: 0.3150 - val_accuracy: 0.8698\n",
      "Epoch 130/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8659 - val_loss: 0.3149 - val_accuracy: 0.8705\n",
      "Epoch 131/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8660 - val_loss: 0.3153 - val_accuracy: 0.8695\n",
      "Epoch 132/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8665 - val_loss: 0.3149 - val_accuracy: 0.8703\n",
      "Epoch 133/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8660 - val_loss: 0.3149 - val_accuracy: 0.8703\n",
      "Epoch 134/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8661 - val_loss: 0.3150 - val_accuracy: 0.8696\n",
      "Epoch 135/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8659 - val_loss: 0.3150 - val_accuracy: 0.8703\n",
      "Epoch 136/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8661 - val_loss: 0.3150 - val_accuracy: 0.8702\n",
      "Epoch 137/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8660 - val_loss: 0.3149 - val_accuracy: 0.8705\n",
      "Epoch 138/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8657 - val_loss: 0.3149 - val_accuracy: 0.8701\n",
      "Epoch 139/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8663 - val_loss: 0.3151 - val_accuracy: 0.8707\n",
      "Epoch 140/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8657 - val_loss: 0.3148 - val_accuracy: 0.8701\n",
      "Epoch 141/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8660 - val_loss: 0.3153 - val_accuracy: 0.8695\n",
      "Epoch 142/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8655 - val_loss: 0.3154 - val_accuracy: 0.8701\n",
      "Epoch 143/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8660 - val_loss: 0.3149 - val_accuracy: 0.8697\n",
      "Epoch 144/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8657 - val_loss: 0.3148 - val_accuracy: 0.8698\n",
      "Epoch 145/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8660 - val_loss: 0.3148 - val_accuracy: 0.8707\n",
      "Epoch 146/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8661 - val_loss: 0.3149 - val_accuracy: 0.8701\n",
      "Epoch 147/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8661 - val_loss: 0.3149 - val_accuracy: 0.8701\n",
      "Epoch 148/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8658 - val_loss: 0.3150 - val_accuracy: 0.8700\n",
      "Epoch 149/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8661 - val_loss: 0.3149 - val_accuracy: 0.8700\n",
      "Epoch 150/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8660 - val_loss: 0.3152 - val_accuracy: 0.8697\n",
      "Epoch 151/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3149 - val_accuracy: 0.8704\n",
      "Epoch 152/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8663 - val_loss: 0.3148 - val_accuracy: 0.8706\n",
      "Epoch 153/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8663 - val_loss: 0.3152 - val_accuracy: 0.8699\n",
      "Epoch 154/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8655 - val_loss: 0.3149 - val_accuracy: 0.8702\n",
      "Epoch 155/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8659 - val_loss: 0.3151 - val_accuracy: 0.8702\n",
      "Epoch 156/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8657 - val_loss: 0.3148 - val_accuracy: 0.8707\n",
      "Epoch 157/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8657 - val_loss: 0.3150 - val_accuracy: 0.8704\n",
      "Epoch 158/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3152 - val_accuracy: 0.8700\n",
      "Epoch 159/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8661 - val_loss: 0.3148 - val_accuracy: 0.8703\n",
      "Epoch 160/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8656 - val_loss: 0.3149 - val_accuracy: 0.8705\n",
      "Epoch 161/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3198 - accuracy: 0.8660 - val_loss: 0.3150 - val_accuracy: 0.8707\n",
      "Epoch 162/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3150 - val_accuracy: 0.8693\n",
      "Epoch 163/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8658 - val_loss: 0.3151 - val_accuracy: 0.8699\n",
      "Epoch 164/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8659 - val_loss: 0.3149 - val_accuracy: 0.8706\n",
      "Epoch 165/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8656 - val_loss: 0.3149 - val_accuracy: 0.8701\n",
      "Epoch 166/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8660 - val_loss: 0.3153 - val_accuracy: 0.8694\n",
      "Epoch 167/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8659 - val_loss: 0.3150 - val_accuracy: 0.8698\n",
      "Epoch 168/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8665 - val_loss: 0.3154 - val_accuracy: 0.8703\n",
      "Epoch 169/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8657 - val_loss: 0.3150 - val_accuracy: 0.8701\n",
      "Epoch 170/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8658 - val_loss: 0.3150 - val_accuracy: 0.8702\n",
      "Epoch 171/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3152 - val_accuracy: 0.8697\n",
      "Epoch 172/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8655 - val_loss: 0.3151 - val_accuracy: 0.8699\n",
      "Epoch 173/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8661 - val_loss: 0.3148 - val_accuracy: 0.8701\n",
      "Epoch 174/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8658 - val_loss: 0.3149 - val_accuracy: 0.8701\n",
      "Epoch 175/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8661 - val_loss: 0.3149 - val_accuracy: 0.8697\n",
      "Epoch 176/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8658 - val_loss: 0.3149 - val_accuracy: 0.8703\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8662 - val_loss: 0.3148 - val_accuracy: 0.8702\n",
      "Epoch 178/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3198 - accuracy: 0.8664 - val_loss: 0.3151 - val_accuracy: 0.8708\n",
      "Epoch 179/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8657 - val_loss: 0.3150 - val_accuracy: 0.8702\n",
      "Epoch 180/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8670 - val_loss: 0.3151 - val_accuracy: 0.8704\n",
      "Epoch 181/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8666 - val_loss: 0.3154 - val_accuracy: 0.8696\n",
      "Epoch 182/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3148 - val_accuracy: 0.8703\n",
      "Epoch 183/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8659 - val_loss: 0.3150 - val_accuracy: 0.8704\n",
      "Epoch 184/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8663 - val_loss: 0.3151 - val_accuracy: 0.8700\n",
      "Epoch 185/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8656 - val_loss: 0.3150 - val_accuracy: 0.8701\n",
      "Epoch 186/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8660 - val_loss: 0.3153 - val_accuracy: 0.8698\n",
      "Epoch 187/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8657 - val_loss: 0.3152 - val_accuracy: 0.8697\n",
      "Epoch 188/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8660 - val_loss: 0.3156 - val_accuracy: 0.8697\n",
      "Epoch 189/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8657 - val_loss: 0.3149 - val_accuracy: 0.8699\n",
      "Epoch 190/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8669 - val_loss: 0.3150 - val_accuracy: 0.8701\n",
      "Epoch 191/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8660 - val_loss: 0.3151 - val_accuracy: 0.8694\n",
      "Epoch 192/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8663 - val_loss: 0.3148 - val_accuracy: 0.8704\n",
      "Epoch 193/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8657 - val_loss: 0.3151 - val_accuracy: 0.8702\n",
      "Epoch 194/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8664 - val_loss: 0.3153 - val_accuracy: 0.8696\n",
      "Epoch 195/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8666 - val_loss: 0.3150 - val_accuracy: 0.8702\n",
      "Epoch 196/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8665 - val_loss: 0.3149 - val_accuracy: 0.8706\n",
      "Epoch 197/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8664 - val_loss: 0.3151 - val_accuracy: 0.8697\n",
      "Epoch 198/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8657 - val_loss: 0.3149 - val_accuracy: 0.8705\n",
      "Epoch 199/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8666 - val_loss: 0.3150 - val_accuracy: 0.8706\n",
      "Epoch 200/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8661 - val_loss: 0.3151 - val_accuracy: 0.8707\n",
      "Epoch 201/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8660 - val_loss: 0.3148 - val_accuracy: 0.8698\n",
      "Epoch 202/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8663 - val_loss: 0.3149 - val_accuracy: 0.8703\n",
      "Epoch 203/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8657 - val_loss: 0.3153 - val_accuracy: 0.8699\n",
      "Epoch 204/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8661 - val_loss: 0.3151 - val_accuracy: 0.8706\n",
      "Epoch 205/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8659 - val_loss: 0.3150 - val_accuracy: 0.8697\n",
      "Epoch 206/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8655 - val_loss: 0.3152 - val_accuracy: 0.8700\n",
      "Epoch 207/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8657 - val_loss: 0.3151 - val_accuracy: 0.8701\n",
      "Epoch 208/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8661 - val_loss: 0.3153 - val_accuracy: 0.8704\n",
      "Epoch 209/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8656 - val_loss: 0.3151 - val_accuracy: 0.8699\n",
      "Epoch 210/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8657 - val_loss: 0.3150 - val_accuracy: 0.8703\n",
      "Epoch 211/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8659 - val_loss: 0.3150 - val_accuracy: 0.8703\n",
      "Epoch 212/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8660 - val_loss: 0.3150 - val_accuracy: 0.8701\n",
      "Epoch 213/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8666 - val_loss: 0.3149 - val_accuracy: 0.8704\n",
      "Epoch 214/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8661 - val_loss: 0.3149 - val_accuracy: 0.8704\n",
      "Epoch 215/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8663 - val_loss: 0.3153 - val_accuracy: 0.8703\n",
      "Epoch 216/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8663 - val_loss: 0.3150 - val_accuracy: 0.8704\n",
      "Epoch 217/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8659 - val_loss: 0.3150 - val_accuracy: 0.8695\n",
      "Epoch 218/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8656 - val_loss: 0.3154 - val_accuracy: 0.8698\n",
      "Epoch 219/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8664 - val_loss: 0.3150 - val_accuracy: 0.8695\n",
      "Epoch 220/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3149 - val_accuracy: 0.8702\n",
      "Epoch 221/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8659 - val_loss: 0.3153 - val_accuracy: 0.8701\n",
      "Epoch 222/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8663 - val_loss: 0.3149 - val_accuracy: 0.8701\n",
      "Epoch 223/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8652 - val_loss: 0.3154 - val_accuracy: 0.8700\n",
      "Epoch 224/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8659 - val_loss: 0.3152 - val_accuracy: 0.8702\n",
      "Epoch 225/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8657 - val_loss: 0.3150 - val_accuracy: 0.8703\n",
      "Epoch 226/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8664 - val_loss: 0.3153 - val_accuracy: 0.8703\n",
      "Epoch 227/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8656 - val_loss: 0.3152 - val_accuracy: 0.8700\n",
      "Epoch 228/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8661 - val_loss: 0.3152 - val_accuracy: 0.8701\n",
      "Epoch 229/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3150 - val_accuracy: 0.8698\n",
      "Epoch 230/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8660 - val_loss: 0.3152 - val_accuracy: 0.8701\n",
      "Epoch 231/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3198 - accuracy: 0.8661 - val_loss: 0.3149 - val_accuracy: 0.8702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8658 - val_loss: 0.3148 - val_accuracy: 0.8700\n",
      "Epoch 233/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8659 - val_loss: 0.3149 - val_accuracy: 0.8702\n",
      "Epoch 234/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8660 - val_loss: 0.3149 - val_accuracy: 0.8702\n",
      "Epoch 235/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8663 - val_loss: 0.3155 - val_accuracy: 0.8691\n",
      "Epoch 236/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3150 - val_accuracy: 0.8702\n",
      "Epoch 237/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3198 - accuracy: 0.8661 - val_loss: 0.3159 - val_accuracy: 0.8692\n",
      "Epoch 238/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8660 - val_loss: 0.3150 - val_accuracy: 0.8695\n",
      "Epoch 239/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3198 - accuracy: 0.8663 - val_loss: 0.3152 - val_accuracy: 0.8699\n",
      "Epoch 240/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8657 - val_loss: 0.3152 - val_accuracy: 0.8701\n",
      "Epoch 241/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8662 - val_loss: 0.3150 - val_accuracy: 0.8703\n",
      "Epoch 242/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8657 - val_loss: 0.3150 - val_accuracy: 0.8701\n",
      "Epoch 243/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3150 - val_accuracy: 0.8702\n",
      "Epoch 244/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8656 - val_loss: 0.3149 - val_accuracy: 0.8705\n",
      "Epoch 245/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8663 - val_loss: 0.3149 - val_accuracy: 0.8705\n",
      "Epoch 246/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8663 - val_loss: 0.3152 - val_accuracy: 0.8695\n",
      "Epoch 247/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8656 - val_loss: 0.3152 - val_accuracy: 0.8699\n",
      "Epoch 248/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8659 - val_loss: 0.3149 - val_accuracy: 0.8701\n",
      "Epoch 249/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8658 - val_loss: 0.3151 - val_accuracy: 0.8699\n",
      "Epoch 250/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3149 - val_accuracy: 0.8705\n",
      "Epoch 251/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3152 - val_accuracy: 0.8703\n",
      "Epoch 252/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3198 - accuracy: 0.8663 - val_loss: 0.3148 - val_accuracy: 0.8703\n",
      "Epoch 253/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8664 - val_loss: 0.3152 - val_accuracy: 0.8701\n",
      "Epoch 254/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8661 - val_loss: 0.3149 - val_accuracy: 0.8705\n",
      "Epoch 255/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8663 - val_loss: 0.3150 - val_accuracy: 0.8704\n",
      "Epoch 256/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8662 - val_loss: 0.3149 - val_accuracy: 0.8700\n",
      "Epoch 257/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8669 - val_loss: 0.3149 - val_accuracy: 0.8703\n",
      "Epoch 258/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8660 - val_loss: 0.3149 - val_accuracy: 0.8703\n",
      "Epoch 259/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8660 - val_loss: 0.3152 - val_accuracy: 0.8700\n",
      "Epoch 260/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8664 - val_loss: 0.3151 - val_accuracy: 0.8699\n",
      "Epoch 261/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3150 - val_accuracy: 0.8704\n",
      "Epoch 262/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8658 - val_loss: 0.3151 - val_accuracy: 0.8701\n",
      "Epoch 263/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8660 - val_loss: 0.3156 - val_accuracy: 0.8698\n",
      "Epoch 264/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8657 - val_loss: 0.3152 - val_accuracy: 0.8694\n",
      "Epoch 265/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8658 - val_loss: 0.3149 - val_accuracy: 0.8702\n",
      "Epoch 266/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8659 - val_loss: 0.3155 - val_accuracy: 0.8702\n",
      "Epoch 267/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3149 - val_accuracy: 0.8701\n",
      "Epoch 268/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8663 - val_loss: 0.3149 - val_accuracy: 0.8706\n",
      "Epoch 269/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8666 - val_loss: 0.3151 - val_accuracy: 0.8700\n",
      "Epoch 270/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3200 - accuracy: 0.8659 - val_loss: 0.3152 - val_accuracy: 0.8701\n",
      "Epoch 271/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8661 - val_loss: 0.3150 - val_accuracy: 0.8701\n",
      "Epoch 272/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8660 - val_loss: 0.3151 - val_accuracy: 0.8702\n",
      "Epoch 273/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3150 - val_accuracy: 0.8702\n",
      "Epoch 274/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8658 - val_loss: 0.3152 - val_accuracy: 0.8700\n",
      "Epoch 275/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8655 - val_loss: 0.3151 - val_accuracy: 0.8702\n",
      "Epoch 276/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8663 - val_loss: 0.3149 - val_accuracy: 0.8703\n",
      "Epoch 277/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8656 - val_loss: 0.3151 - val_accuracy: 0.8700\n",
      "Epoch 278/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8655 - val_loss: 0.3154 - val_accuracy: 0.8697\n",
      "Epoch 279/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8653 - val_loss: 0.3154 - val_accuracy: 0.8702\n",
      "Epoch 280/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8666 - val_loss: 0.3150 - val_accuracy: 0.8701\n",
      "Epoch 281/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8664 - val_loss: 0.3150 - val_accuracy: 0.8705\n",
      "Epoch 282/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3152 - val_accuracy: 0.8700\n",
      "Epoch 283/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8659 - val_loss: 0.3155 - val_accuracy: 0.8697\n",
      "Epoch 284/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8657 - val_loss: 0.3151 - val_accuracy: 0.8700\n",
      "Epoch 285/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8664 - val_loss: 0.3152 - val_accuracy: 0.8705\n",
      "Epoch 286/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8663 - val_loss: 0.3153 - val_accuracy: 0.8699\n",
      "Epoch 287/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8660 - val_loss: 0.3154 - val_accuracy: 0.8699\n",
      "Epoch 288/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3200 - accuracy: 0.8659 - val_loss: 0.3151 - val_accuracy: 0.8702\n",
      "Epoch 289/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3151 - val_accuracy: 0.8701\n",
      "Epoch 290/300\n",
      "27188/27188 [==============================] - 0s 12us/step - loss: 0.3199 - accuracy: 0.8668 - val_loss: 0.3149 - val_accuracy: 0.8702\n",
      "Epoch 291/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8660 - val_loss: 0.3149 - val_accuracy: 0.8703\n",
      "Epoch 292/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3150 - val_accuracy: 0.8699\n",
      "Epoch 293/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3150 - val_accuracy: 0.8702\n",
      "Epoch 294/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8663 - val_loss: 0.3150 - val_accuracy: 0.8703\n",
      "Epoch 295/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8662 - val_loss: 0.3150 - val_accuracy: 0.8703\n",
      "Epoch 296/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8663 - val_loss: 0.3151 - val_accuracy: 0.8696\n",
      "Epoch 297/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8664 - val_loss: 0.3152 - val_accuracy: 0.8699\n",
      "Epoch 298/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8664 - val_loss: 0.3152 - val_accuracy: 0.8701\n",
      "Epoch 299/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8659 - val_loss: 0.3154 - val_accuracy: 0.8699\n",
      "Epoch 300/300\n",
      "27188/27188 [==============================] - 0s 13us/step - loss: 0.3199 - accuracy: 0.8660 - val_loss: 0.3150 - val_accuracy: 0.8703\n"
     ]
    }
   ],
   "source": [
    "history_domi = model.fit(X_train_domi, y_train_domi, epochs = 300, batch_size = batch_size, validation_data=(X_val_domi, y_val_domi) )\n",
    "history_recess = model.fit(X_train_recess, y_train_recess, epochs = 300, batch_size = batch_size, validation_data=(X_val_recess, y_val_recess))\n",
    "history = model.fit(X_train, y_train, epochs = 300, batch_size = batch_size, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(history_domi)\n",
    "draw(history_recess)\n",
    "draw(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_domi_testhat = model.predict(X_test_domi)\n",
    "y_recess_testhat = model\n",
    "drawROC(y_test_domi, y_domi_testhat, label = 'dominant', lastone = True, title = \"neuron network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sanEnv)",
   "language": "python",
   "name": "sanenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
