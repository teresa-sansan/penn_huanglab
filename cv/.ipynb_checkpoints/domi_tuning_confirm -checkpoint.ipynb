{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters = kernal:rbf, C:1, gamma = 0.1\n",
      "testing accuracy = 0.845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn import metrics, svm\n",
    "from test_function import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#omit = pd.read_csv(\"/storage/home/jkl5991/work/project/unannotated_omit_std.tsv\", sep = \"\\t\")\n",
    "omit = pd.read_csv(\"/storage/home/jkl5991/work/project/dominant_std.tsv\", sep = \"\\t\")\n",
    "x_column = ['SIFT_pred','LRT_pred', 'MA_pred', 'PROVEN_pred', 'SLR_score', 'SIFT_score','LRT_omega', \n",
    "                'MA_score', 'PROVEN_score', 'Grantham', 'HMMEntropy','HMMRelEntropy', 'PredRSAB', 'PredRSAI', \n",
    "                'PredRSAE','PredBFactorF', 'PredBFactorM', 'PredBFactorS', 'PredStabilityH','PredStabilityM', \n",
    "                'PredStabilityL', 'PredSSE', 'PredSSH','PredSSC', 'dscore', 'phyloP_pri', 'phyloP_mam','phyloP_ver','RNA_seq','UNEECON']\n",
    "y_column = ['clinvar_result']\n",
    "\n",
    "#overall model\n",
    "y = omit.loc[:,y_column].values.flatten()\n",
    "X = omit.loc[:,x_column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "\n",
    "print(\"# Tuning hyper-parameters = kernal:rbf, C:1, gamma = 0.1\")\n",
    "svc = SVC(kernel = \"rbf\", C = 1, gamma = 0.1)\n",
    "svc.fit(X_train, y_train)\n",
    "train_pred = svc.predict(X_train)\n",
    "train_acc = accuracy_score(y_train,train_pred)\n",
    "test_pred = svc.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, test_pred)\n",
    "#print(\"training accuracy = %r\\n\"%train_acc)\n",
    "print(\"testing accuracy = %0.3f\\n\"%test_acc )\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters = kernal:rbf, C:10, gamma = 0.01\n",
      "testing accuracy = 0.850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"# Tuning hyper-parameters = kernal:rbf, C:10, gamma = 0.01\")\n",
    "svc = SVC(kernel = \"rbf\", C = 10, gamma = 0.01)\n",
    "svc.fit(X_train, y_train)\n",
    "train_pred = svc.predict(X_train)\n",
    "train_acc = accuracy_score(y_train,train_pred)\n",
    "test_pred = svc.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, test_pred)\n",
    "#print(\"training accuracy = %r\\n\"%train_acc)\n",
    "print(\"testing accuracy = %0.3f\\n\"%test_acc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for recall\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/jkl5991/.conda/envs/sanEnv/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "With score : 0.853\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.847 (+/-0.033) for {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.853 (+/-0.036) for {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.849 (+/-0.042) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.842 (+/-0.032) for {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       319\n",
      "           1       0.84      0.85      0.85       319\n",
      "\n",
      "    accuracy                           0.84       638\n",
      "   macro avg       0.84      0.84      0.84       638\n",
      "weighted avg       0.84      0.84      0.84       638\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tunning domi\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "tuned_parameters = [{'kernel':['rbf'],'gamma':[0.01, 0.1],'C':[1, 10]}]\n",
    "\n",
    "\n",
    "def tuning(X_train, X_test, y_train, y_test):\n",
    "    print(\"# Tuning hyper-parameters for %s\" % 'recall')\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, scoring='%s_macro' % 'recall')\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"With score : %0.3f\\n\"%clf.best_score_)\n",
    "    print(\"Grid scores on development set:\\n\")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\\n\")\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\\n\")\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "tuning(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sanEnv)",
   "language": "python",
   "name": "sanenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
